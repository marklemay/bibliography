@string{acm-popl        = "ACM Symposium on Principles of Programming Languages"}

@misc{lampropoulos19,
  author = {Leonidas Lampropoulos and Michael Hicks and
            Benjamin C. Pierce},
  title  = {Coverage Guided, Property Based Testing},
  year   = 2019,
  month  = apr,
  short  = {https://www.cs.umd.edu/~mwh/papers/lampropoulos19fuzzchick.html},
  slides = {http://www.cis.upenn.edu/~bcpierce/papers/fuzzchick-hcss2019.pdf},
  note   = {To appear in PACMPL / OOPSLA 2019},
  bcp    = {Yes},
  plclub = {Yes},
  keys   = {verification}
}

@article{quickcheck,
  title     = {QuickCheck: a lightweight tool for random testing of Haskell programs},
  author    = {Claessen, Koen and Hughes, John},
  journal   = {ACM SIGPLAN Notices},
  volume    = {46},
  number    = {4},
  pages     = {53--64},
  year      = {2001},
  publisher = {ACM New York, NY, USA}
}

@incollection{martin1975,
  title     = {An intuitionistic theory of types: Predicative part},
  author    = {Martin-L{\"o}f, Per},
  booktitle = {Studies in Logic and the Foundations of Mathematics},
  volume    = {80},
  pages     = {73--118},
  year      = {1975},
  publisher = {Elsevier}
}


@article{jia2010dependent,
  author     = {Jia, Limin and Zhao, Jianzhou and Sj{\"o}berg, Vilhelm and Weirich, Stephanie},
  title      = {Dependent Types and Program Equivalence},
  year       = {2010},
  issue_date = {January 2010},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {45},
  number     = {1},
  issn       = {0362-1340},
  url        = {https://doi.org/10.1145/1707801.1706333},
  doi        = {10.1145/1707801.1706333},
  abstract   = {The definition of type equivalence is one of the most important design issues for
                any typed language. In dependently typed languages, because terms appear in types,
                this definition must rely on a definition of term equivalence. In that case, decidability
                of type checking requires decidability for the term equivalence relation.Almost all
                dependently-typed languages require this relation to be decidable. Some, such as Coq,
                Epigram or Agda, do so by employing analyses to force all programs to terminate. Conversely,
                others, such as DML, ATS, Ωmega, or Haskell, allow nonterminating computation, but
                do not allow those terms to appear in types. Instead, they identify a terminating
                index language and use singleton types to connect indices to computation. In both
                cases, decidable type checking comes at a cost, in terms of complexity and expressiveness.Conversely,
                the benefits to be gained by decidable type checking are modest. Termination analyses
                allow dependently typed programs to verify total correctness properties. However,
                decidable type checking is not a prerequisite for type safety. Furthermore, decidability
                does not imply tractability. A decidable approximation of program equivalence may
                not be useful in practice.Therefore, we take a different approach: instead of a fixed
                notion for term equivalence, we parameterize our type system with an abstract relation
                that is not necessarily decidable. We then design a novel set of typing rules that
                require only weak properties of this abstract relation in the proof of the preservation
                and progress lemmas. This design provides flexibility: we compare valid instantiations
                of term equivalence which range from beta-equivalence, to contextual equivalence,
                to some exotic equivalences.},
  journal    = {ACM SIGPLAN Notices},
  month      = jan,
  pages      = {275--286},
  numpages   = {12},
  keywords   = {program equivalence, dependent types}
}


@inproceedings{kimmell2012equational,
  title     = {Equational reasoning about programs with general recursion and call-by-value semantics},
  author    = {Kimmell, Garrin and Stump, Aaron and Eades III, Harley D and Fu, Peng and Sheard, Tim and Weirich, Stephanie and Casinghino, Chris and Sj{\"o}berg, Vilhelm and Collins, Nathan and Ahn, Ki Yung},
  booktitle = {Proceedings of the sixth workshop on Programming languages meets program verification},
  pages     = {15--26},
  year      = {2012}
}

@article{sjoberg2012irrelevance,
  title   = {Irrelevance, heterogeneous equality, and call-by-value dependent type systems},
  author  = {Sj{\"o}berg, Vilhelm and Casinghino, Chris and Ahn, Ki Yung and Collins, Nathan and Eades III, Harley D and Fu, Peng and Kimmell, Garrin and Sheard, Tim and Stump, Aaron and Weirich, Stephanie},
  journal = {Mathematically Structured Functional Programming},
  volume  = {76},
  pages   = {112--162},
  year    = {2012}
}


@article{casinghino2014combining,
  title     = {Combining proofs and programs in a dependently typed language},
  author    = {Casinghino, Chris and Sj{\"o}berg, Vilhelm and Weirich, Stephanie},
  journal   = {ACM SIGPLAN Notices},
  volume    = {49},
  number    = {1},
  pages     = {33--45},
  year      = {2014},
  publisher = {ACM New York, NY, USA}
}

@phdthesis{casinghino2014combiningthesis,
  title  = {Combining proofs and programs},
  author = {Casinghino, Chris},
  school = {University of Pennsylvania},
  year   = {2014}
}

@inproceedings{sjoberg2015programming,
  title     = {Programming up to congruence},
  author    = {Sj{\"o}berg, Vilhelm and Weirich, Stephanie},
  booktitle = {Proceedings of the 42nd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
  pages     = {369--382},
  year      = {2015}
}


@phdthesis{sjoberg2015dependently,
  title  = {A dependently typed language with nontermination},
  author = {Sj{\"o}berg, Vilhelm},
  school = {University of Pennsylvania},
  year   = {2015}
}


@inproceedings{weirich13towards,
  title     = {Towards dependently typed Haskell: System FC with kind equality},
  author    = {Weirich, Stephanie and Hsu, Justin and Eisenberg, Richard A},
  booktitle = {Proceedings of the 18th ACM SIGPLAN International Conference on Functional Programming, ICFP},
  volume    = {13}
}

@book{eisenberg2016dependent,
  title     = {Dependent types in haskell: Theory and practice},
  author    = {Eisenberg, Richard A},
  year      = {2016},
  publisher = {University of Pennsylvania}
}

@article{brady2013idris,
  title     = {Idris, a general-purpose dependently typed programming language: Design and implementation},
  author    = {Brady, Edwin},
  journal   = {Journal of functional programming},
  volume    = {23},
  number    = {5},
  pages     = {552--593},
  year      = {2013},
  publisher = {Cambridge University Press}
}
@article{JFP:9060502,
  author   = {Brady, Edwin},
  title    = {Idris, a general-purpose dependently typed programming language: Design and implementation},
  journal  = {Journal of Functional Programming},
  volume   = {23},
  issue    = {05},
  month    = {9},
  year     = {2013},
  issn     = {1469-7653},
  pages    = {552--593},
  numpages = {42},
  doi      = {10.1017/S095679681300018X},
  url      = {https://journals.cambridge.org/article_S095679681300018X}
}

@article{weirich2017specification,
  title     = {A specification for dependent types in Haskell},
  author    = {Weirich, Stephanie and Voizard, Antoine and de Amorim, Pedro Henrique Azevedo and Eisenberg, Richard A},
  journal   = {Proceedings of the ACM on Programming Languages},
  volume    = {1},
  number    = {ICFP},
  pages     = {31},
  year      = {2017},
  publisher = {ACM}
}


@incollection{tikovsky2017concolic,
  title     = {Concolic Testing of Functional Logic Programs},
  author    = {Tikovsky, Jan Rasmus},
  booktitle = {Declarative Programming and Knowledge Management},
  pages     = {169--186},
  year      = {2017},
  publisher = {Springer}
}

@inproceedings{hallahan2019lazy,
  title     = {Lazy counterfactual symbolic execution},
  author    = {Hallahan, William T and Xue, Anton and Bland, Maxwell Troy and Jhala, Ranjit and Piskac, Ruzica},
  booktitle = {Proceedings of the 40th ACM SIGPLAN Conference on Programming Language Design and Implementation},
  pages     = {411--424},
  year      = {2019}
}

@article{giantsios2017concolic,
  title     = {Concolic testing for functional languages},
  author    = {Giantsios, Aggelos and Papaspyrou, Nikolaos and Sagonas, Konstantinos},
  journal   = {Science of Computer Programming},
  volume    = {147},
  pages     = {109--134},
  year      = {2017},
  publisher = {Elsevier}
}


@inproceedings{hallahan2017building,
  title     = {Building a Symbolic Execution Engine for Haskell},
  author    = {Hallahan, William and Xue, Anton and Piskac, Ruzica},
  booktitle = {Proceedings of the 8th Workshop on Tools for Automatic Program Analysis (TAPAS 2017), New York, NY, USA, August 29},
  year      = {2017}
}


@inproceedings{palacios2015concolic,
  title        = {Concolic execution in functional programming by program instrumentation},
  author       = {Palacios, Adri{\'a}n and Vidal, Germ{\'a}n},
  booktitle    = {International Symposium on Logic-Based Program Synthesis and Transformation},
  pages        = {277--292},
  year         = {2015},
  organization = {Springer}
}

@article{pretnar2014inferring,
  title     = {Inferring Algebraic Effects},
  author    = {Pretnar, Matija},
  journal   = {Logical Methods in Computer Science},
  volume    = {10},
  year      = {2014},
  publisher = {Episciences. org}
}

@inproceedings{brady2013programming,
  title     = {Programming and reasoning with algebraic effects and dependent types},
  author    = {Brady, Edwin},
  booktitle = {Proceedings of the 18th ACM SIGPLAN international conference on Functional programming},
  pages     = {133--144},
  year      = {2013}
}

@article{ahman2017handling,
  title     = {Handling fibred algebraic effects},
  author    = {Ahman, Danel},
  journal   = {Proceedings of the ACM on Programming Languages},
  volume    = {2},
  number    = {POPL},
  pages     = {1--29},
  year      = {2017},
  publisher = {ACM New York, NY, USA}
}

@article{ahman2017fibred,
  title   = {Fibred computational effects},
  author  = {Ahman, Danel},
  journal = {arXiv preprint arXiv:1710.02594},
  year    = {2017}
}

@book{HoTTbook,
  author      = {The Univalent Foundations Program},
  institution = {Institute for Advanced Study},
  title       = {Homotopy type theory: Univalent foundations of mathematics},
  year        = {2013}
}

@article{altenkirch2006towards,
  title   = {Towards observational type theory},
  author  = {Altenkirch, Thorsten and McBride, Conor},
  journal = {Manuscript, available online},
  year    = {2006}
}
@inproceedings{altenkirch2007observational,
  title     = {Observational equality, now!},
  author    = {Altenkirch, Thorsten and McBride, Conor and Swierstra, Wouter},
  booktitle = {Proceedings of the 2007 workshop on Programming languages meets program verification},
  pages     = {57--68},
  year      = {2007}
}
@article{mazzoli2013bertus,
  title  = {Bertus: Implementing Observational Equality},
  author = {Mazzoli, Francesco},
  year   = {2013}
}

@inproceedings{cha2012unleashing,
  title        = {Unleashing mayhem on binary code},
  author       = {Cha, Sang Kil and Avgerinos, Thanassis and Rebert, Alexandre and Brumley, David},
  booktitle    = {2012 IEEE Symposium on Security and Privacy},
  pages        = {380--394},
  year         = {2012},
  organization = {IEEE}
}

@article{o2019incorrectness,
  title     = {Incorrectness logic},
  author    = {O'Hearn, Peter W},
  journal   = {Proceedings of the ACM on Programming Languages},
  volume    = {4},
  number    = {POPL},
  pages     = {1--32},
  year      = {2019},
  publisher = {ACM New York, NY, USA}
}

@article{de2008higher,
  title     = {Higher-Order Unification: A structural relation between Huet's method and the one based on explicit substitutions},
  author    = {de Moura, Fl{\'a}vio LC and Ayala-Rinc{\'o}n, Mauricio and Kamareddine, Fairouz},
  journal   = {Journal of Applied Logic},
  volume    = {6},
  number    = {1},
  pages     = {72--108},
  year      = {2008},
  publisher = {Elsevier}
}

@inproceedings{pfenning1991unification,
  title     = {Unification and anti-unification in the Calculus of Constructions},
  author    = {Pfenning, Frank},
  booktitle = {LICS},
  volume    = {91},
  pages     = {74--85},
  year      = {1991}
}

@inproceedings{hanus1995curry,
  title     = {Curry: A truly functional logic language},
  author    = {Hanus, Michael and Kuchen, Herbert and Moreno-Navarro, Juan Jose},
  booktitle = {Proc. ILPS},
  volume    = {95},
  number    = {5},
  pages     = {95--107},
  year      = {1995}
}

@inproceedings{nipkow1991higher,
  title     = {Higher-order critical pairs},
  author    = {Nipkow, Tobias},
  booktitle = {Proceedings 1991 Sixth Annual IEEE Symposium on Logic in Computer Science},
  pages     = {342--343},
  year      = {1991}
}

@inproceedings{honda2004compositional,
  title     = {A compositional logic for polymorphic higher-order functions},
  author    = {Honda, Kohei and Yoshida, Nobuko},
  booktitle = {Proceedings of the 6th ACM SIGPLAN international conference on Principles and practice of declarative programming},
  pages     = {191--202},
  year      = {2004}
}

@inproceedings{yoshida2007logical,
  title        = {Logical reasoning for higher-order functions with local state},
  author       = {Yoshida, Nobuko and Honda, Kohei and Berger, Martin},
  booktitle    = {International Conference on Foundations of Software Science and Computational Structures},
  pages        = {361--377},
  year         = {2007},
  organization = {Springer}
}

@inproceedings{honda2005observationally,
  title        = {An observationally complete program logic for imperative higher-order functions},
  author       = {Honda, Kohei and Yoshida, Nobuko and Berger, Martin},
  booktitle    = {20th Annual IEEE Symposium on Logic in Computer Science (LICS'05)},
  pages        = {270--279},
  year         = {2005},
  organization = {IEEE}
}

@inproceedings{honda2006descriptive,
  title        = {Descriptive and relative completeness of logics for higher-order functions},
  author       = {Honda, Kohei and Berger, Martin and Yoshida, Nobuko},
  booktitle    = {International Colloquium on Automata, Languages, and Programming},
  pages        = {360--371},
  year         = {2006},
  organization = {Springer}
}
@inproceedings{berger2005logical,
  title     = {A logical analysis of aliasing in imperative higher-order functions},
  author    = {Berger, Martin and Honda, Kohei and Yoshida, Nobuko},
  booktitle = {Proceedings of the tenth ACM SIGPLAN international conference on Functional programming},
  pages     = {280--293},
  year      = {2005}
}

@inproceedings{regis2008hoare,
  title        = {A Hoare logic for call-by-value functional programs},
  author       = {R{\'e}gis-Gianas, Yann and Pottier, Fran{\c{c}}ois},
  booktitle    = {International Conference on Mathematics of Program Construction},
  pages        = {305--335},
  year         = {2008},
  organization = {Springer}
}

@book{haiyan2003testing,
  title     = {Testing and Proving in Dependent Type Theory},
  author    = {Haiyan, Qiao},
  year      = {2003},
  publisher = {Chalmers University of Technology}
}

@inproceedings{dybjer2003combining,
  title        = {Combining testing and proving in dependent type theory},
  author       = {Dybjer, Peter and Haiyan, Qiao and Takeyama, Makoto},
  booktitle    = {International Conference on Theorem Proving in Higher Order Logics},
  pages        = {188--203},
  year         = {2003},
  organization = {Springer}
}

@inproceedings{dybjer2004random,
  title        = {Random generators for dependent types},
  author       = {Dybjer, Peter and Haiyan, Qiao and Takeyama, Makoto},
  booktitle    = {International Colloquium on Theoretical Aspects of Computing},
  pages        = {341--355},
  year         = {2004},
  organization = {Springer}
}

@phdthesis{lampropoulos2018random,
  title  = {Random Testing for Language Design},
  author = {Lampropoulos, Leonidas},
  year   = {2018},
  school = {University of Pennsylvania}
}

@inproceedings{lampropoulos2017beginner,
  title     = {Beginner's luck: a language for property-based generators},
  author    = {Lampropoulos, Leonidas and Gallois-Wong, Diane and Hri{\c{t}}cu, C{\u{a}}t{\u{a}}lin and Hughes, John and Pierce, Benjamin C and Xia, Li-yao},
  booktitle = {Proceedings of the 44th ACM SIGPLAN Symposium on Principles of Programming Languages},
  pages     = {114--129},
  year      = {2017}
}

@article{lampropoulos2017generating,
  title     = {Generating good generators for inductive relations},
  author    = {Lampropoulos, Leonidas and Paraskevopoulou, Zoe and Pierce, Benjamin C},
  journal   = {Proceedings of the ACM on Programming Languages},
  volume    = {2},
  number    = {POPL},
  pages     = {1--30},
  year      = {2017},
  publisher = {ACM New York, NY, USA}
}

@article{fortzthesis,
  title  = {THESIS/TH{\`E}SE},
  author = {Fortz, Sophie}
}

@book{diaconescu1994category,
  title     = {Category-based semantics for equational and constraint logic programming},
  author    = {Diaconescu, Razvan},
  year      = {1994},
  publisher = {University of Oxford}
}


@incollection{diaconescu1995category,
  title     = {A category-based equational logic semantics to constraint programming},
  author    = {Diaconescu, R{\u{a}}zvan},
  booktitle = {Recent Trends in Data Type Specification},
  pages     = {200--221},
  year      = {1995},
  publisher = {Springer}
}


@article{diaconescu2000category,
  title     = {Category-based constraint logic},
  author    = {Diaconescu, R{\u{a}}zvan},
  journal   = {Mathematical Structures in Computer Science},
  volume    = {10},
  number    = {3},
  pages     = {373--407},
  year      = {2000},
  publisher = {Cambridge University Press}
}

@article{lindblad2008higher,
  title     = {Higher-order proof construction based on first-order narrowing},
  author    = {Lindblad, Fredrik},
  journal   = {Electronic Notes in Theoretical Computer Science},
  volume    = {196},
  pages     = {69--84},
  year      = {2008},
  publisher = {Elsevier}
}

@inproceedings{denes2014quickchick,
  title     = {QuickChick: Property-based testing for Coq},
  author    = {D{\'e}n{\`e}s, Maxime and Hritcu, Catalin and Lampropoulos, Leonidas and Paraskevopoulou, Zoe and Pierce, Benjamin C},
  booktitle = {The Coq Workshop},
  year      = {2014}
}

@inproceedings{jaffar1987constraint,
  title     = {Constraint logic programming},
  author    = {Jaffar, Joxan and Lassez, J-L},
  booktitle = {Proceedings of the 14th ACM SIGACT-SIGPLAN symposium on Principles of programming languages},
  pages     = {111--119},
  year      = {1987}
}

@article{jaffar1994constraint,
  title     = {Constraint logic programming: A survey},
  author    = {Jaffar, Joxan and Maher, Michael J},
  journal   = {The journal of logic programming},
  volume    = {19},
  pages     = {503--581},
  year      = {1994},
  publisher = {Elsevier}
}

@article{10.1145/3371126,
  author     = {P\'{e}drot, Pierre-Marie and Tabareau, Nicolas},
  title      = {The Fire Triangle: How to Mix Substitution, Dependent Elimination, and Effects},
  year       = {2019},
  issue_date = {January 2020},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {4},
  number     = {POPL},
  url        = {https://doi.org/10.1145/3371126},
  doi        = {10.1145/3371126},
  abstract   = {There is a critical tension between substitution, dependent elimination and effects in type theory. In this paper, we crystallize this tension in the form of a no-go theorem that constitutes the fire triangle of type theory. To release this tension, we propose ∂CBPV, an extension of call-by-push-value (CBPV) —a general calculus of effects—to dependent types. Then, by extending to ∂CBPV the well-known decompositions of call-by-name and call-by-value into CBPV, we show why, in presence of effects, dependent elimination must be restricted in call-by-name, and substitution must be restricted in call-by-value. To justify ∂CBPV and show that it is general enough to interpret many kinds of effects, we define various effectful syntactic translations from ∂CBPV to Martin-L\"{o}f type theory: the reader, weaning and forcing translations.},
  journal    = {Proceedings of the ACM on Programming Languages},
  month      = dec,
  articleno  = {58},
  numpages   = {28},
  keywords   = {type theory, effects}
}

@inproceedings{pedrot2018failure,
  title        = {Failure is not an option},
  author       = {P{\'e}drot, Pierre-Marie and Tabareau, Nicolas},
  booktitle    = {European Symposium on Programming},
  pages        = {245--271},
  year         = {2018},
  organization = {Springer}
}

@article{lampropoulos2019coverage,
  title     = {Coverage guided, property based testing},
  author    = {Lampropoulos, Leonidas and Hicks, Michael and Pierce, Benjamin C},
  journal   = {Proceedings of the ACM on Programming Languages},
  volume    = {3},
  number    = {OOPSLA},
  pages     = {1--29},
  year      = {2019},
  publisher = {ACM New York, NY, USA}
}

@article{nguyen2014soft,
  title     = {Soft contract verification},
  author    = {Nguyen, Ph{\'u}c C and Tobin-Hochstadt, Sam and Van Horn, David},
  journal   = {ACM SIGPLAN Notices},
  volume    = {49},
  number    = {9},
  pages     = {139--152},
  year      = {2014},
  publisher = {ACM New York, NY, USA}
}

@article{nguyen2015relatively,
  title     = {Relatively complete counterexamples for higher-order programs},
  author    = {Nguyen, Ph{\'u}c C and Van Horn, David},
  journal   = {ACM SIGPLAN Notices},
  volume    = {50},
  number    = {6},
  pages     = {446--456},
  year      = {2015},
  publisher = {ACM New York, NY, USA}
}

@article{nguyen2017higher,
  title     = {Higher order symbolic execution for contract verification and refutation},
  author    = {Nguyen, Phuc C and Tobin-Hochstadt, Sam and Van Horn, David},
  journal   = {Journal of Functional Programming},
  volume    = {27},
  year      = {2017},
  publisher = {Cambridge University Press}
}

@incollection{hofmann1997syntax,
  title     = {Syntax and semantics of dependent types},
  author    = {Hofmann, Martin},
  booktitle = {Extensional Constructs in Intensional Type Theory},
  pages     = {13--54},
  year      = {1997},
  publisher = {Springer}
}

@misc{2006.11639,
  author = {Shu-Hung You and Robert Bruce Findler and Christos Dimoulas},
  title  = {Dynamic Symbolic Execution of Higher-Order Functions},
  year   = {2020},
  eprint = {arXiv:2006.11639}
}

@book{levy2012call,
  title     = {Call-by-push-value: A Functional/imperative Synthesis},
  author    = {Levy, Paul Blain},
  volume    = {2},
  year      = {2012},
  publisher = {Springer Science \& Business Media}
}

@article{nanevski2005dependent,
  title  = {Dependent type theory of stateful higher-order functions},
  author = {Nanevski, Aleksandar and Morrisett, Greg Gregory},
  year   = {2005}
}

@article{nanevski2008hoare,
  title     = {Hoare type theory, polymorphism and separation},
  author    = {Nanevski, Aleksandar and Morrisett, Greg and Birkedal, Lars},
  journal   = {Journal of Functional Programming},
  volume    = {18},
  number    = {5-6},
  pages     = {865--911},
  year      = {2008},
  publisher = {Cambridge University Press}
}

@phdthesis{norell2007towards,
  author  = {Ulf Norell},
  title   = {Towards a practical programming language based on dependent type
             theory},
  school  = {Department of Computer Science and Engineering, Chalmers University of Technology},
  year    = 2007,
  month   = {September},
  address = {SE-412 96 G\"{o}teborg, Sweden}
}

@article{10.1145/3408984,
  author     = {Palmer, Zachary and Park, Theodore and Smith, Scott and Weng, Shiwei},
  title      = {Higher-Order Demand-Driven Symbolic Evaluation},
  year       = {2020},
  issue_date = {August 2020},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {4},
  number     = {ICFP},
  url        = {https://doi.org/10.1145/3408984},
  doi        = {10.1145/3408984},
  abstract   = {Symbolic backwards execution (SBE) is a useful variation on standard forward symbolic evaluation; it allows a symbolic evaluation to start anywhere in the program and proceed by executing in reverse to the program start. SBE brings goal-directed reasoning to symbolic evaluation and has proven effective in e.g. automated test generation for imperative languages. In this paper we define DDSE, a novel SBE which operates on a functional as opposed to imperative language; furthermore, it is defined as a natural extension of a backwards-executing interpreter. We establish the soundness of DDSE and define a test generation algorithm for this toy language. We report on an initial reference implementation to confirm the correctness of the principles.},
  journal    = {Proceedings of the ACM on Programming Languages},
  month      = aug,
  articleno  = {102},
  numpages   = {28},
  keywords   = {Symbolic Execution, Demand-Driven Execution, Test Generation}
}


@article{10.1145/1090189.1086390,
  author     = {Kiselyov, Oleg and Shan, Chung-chieh and Friedman, Daniel P. and Sabry, Amr},
  title      = {Backtracking, Interleaving, and Terminating Monad Transformers: (Functional Pearl)},
  year       = {2005},
  issue_date = {September 2005},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {40},
  number     = {9},
  issn       = {0362-1340},
  url        = {https://doi.org/10.1145/1090189.1086390},
  doi        = {10.1145/1090189.1086390},
  abstract   = {We design and implement a library for adding backtracking computations to any Haskell monad. Inspired by logic programming, our library provides, in addition to the operations required by the MonadPlus interface, constructs for fair disjunctions, fair conjunctions, conditionals, pruning, and an expressive top-level interface. Implementing these additional constructs is easy in models of backtracking based on streams, but not known to be possible in continuation-based models. We show that all these additional constructs can be generically and monadically realized using a single primitive msplit. We present two implementations of the library: one using success and failure continuations; and the other using control operators for manipulating delimited continuations.},
  journal    = {ACM SIGPLAN Notices},
  month      = sep,
  pages      = {192–203},
  numpages   = {12},
  keywords   = {logic programming, streams, Haskell, control delimiters, continuations, Prolog}
}

@inproceedings{10.1145/1086365.1086390,
  author    = {Kiselyov, Oleg and Shan, Chung-chieh and Friedman, Daniel P. and Sabry, Amr},
  title     = {Backtracking, Interleaving, and Terminating Monad Transformers: (Functional Pearl)},
  year      = {2005},
  isbn      = {1595930647},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/1086365.1086390},
  doi       = {10.1145/1086365.1086390},
  abstract  = {We design and implement a library for adding backtracking computations to any Haskell monad. Inspired by logic programming, our library provides, in addition to the operations required by the MonadPlus interface, constructs for fair disjunctions, fair conjunctions, conditionals, pruning, and an expressive top-level interface. Implementing these additional constructs is easy in models of backtracking based on streams, but not known to be possible in continuation-based models. We show that all these additional constructs can be generically and monadically realized using a single primitive msplit. We present two implementations of the library: one using success and failure continuations; and the other using control operators for manipulating delimited continuations.},
  booktitle = {Proceedings of the Tenth ACM SIGPLAN International Conference on Functional Programming},
  pages     = {192–203},
  numpages  = {12},
  keywords  = {continuations, control delimiters, Prolog, logic programming, streams, Haskell},
  location  = {Tallinn, Estonia},
  series    = {ICFP '05}
}


@article{eremondi2019framework,
  title     = {A framework for improving error messages in dependently-typed languages},
  author    = {Eremondi, Joseph and Swierstra, Wouter and Hage, Jurriaan},
  journal   = {Open Computer Science},
  volume    = {9},
  number    = {1},
  pages     = {1--32},
  year      = {2019},
  publisher = {De Gruyter}
}

@inproceedings{Ren2013ProgrammerCentric,
  abstract             = {{Formal specification is widely employed in the construction of high-quality software.
                          However, there is often a huge gap between formal specification and actual implementation.
                          While there is already a vast body of work on software testing and verification, the task
                          to ensure that an implementation indeed meets its specification is still undeniably of great
                          difficulty. ATS is a programming language equipped with a highly expressive type system
                          that allows the programmer to specify and implement and then verify within the language
                          itself that an implementation meets its specification. In this paper, we present largely
                          through examples a programmer-centric style of program verification that puts emphasis
                          on requesting the programmer to explain in a literate fashion why his or her code works.
                          This is a solid step in the pursuit of software construction that is verifiably correct according
                          to specification.}},
  author               = {Ren, Zhiqiang and Xi, Hongwei},
  booktitle            = {Proceedings of Workshop on Automated Reasoning in Security and Software Verification (ARSEC)},
  citeulike-article-id = {12720618},
  location             = {Lake Placid, New York},
  month                = jun,
  posted-at            = {2013-10-14 06:21:45},
  priority             = {2},
  title                = {{A Programmer-Centric Approach to Program Verification in ATS}},
  year                 = {2013}
}


@inproceedings{10.1145/2951913.2951915,
  author    = {Seidel, Eric L. and Jhala, Ranjit and Weimer, Westley},
  title     = {Dynamic Witnesses for Static Type Errors (or, Ill-Typed Programs Usually Go Wrong)},
  year      = {2016},
  isbn      = {9781450342193},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/2951913.2951915},
  doi       = {10.1145/2951913.2951915},
  abstract  = { Static type errors are a common stumbling block for newcomers to typed functional languages. We present a dynamic approach to explaining type errors by generating counterexample witness inputs that illustrate how an ill-typed program goes wrong. First, given an ill-typed function, we symbolically execute the body to synthesize witness values that make the program go wrong. We prove that our procedure synthesizes general witnesses in that if a witness is found, then for all inhabited input types, there exist values that can make the function go wrong. Second, we show how to extend the above procedure to produce a reduction graph that can be used to interactively visualize and debug witness executions. Third, we evaluate the coverage of our approach on two data sets comprising over 4,500 ill-typed student programs. Our technique is able to generate witnesses for 88% of the programs, and our reduction graph yields small counterexamples for 81% of the witnesses. Finally, we evaluate whether our witnesses help students understand and fix type errors, and find that students presented with our witnesses show a greater understanding of type errors than those presented with a standard error message. },
  booktitle = {Proceedings of the 21st ACM SIGPLAN International Conference on Functional Programming},
  pages     = {228-242},
  numpages  = {15},
  keywords  = {debugging, type errors, testing},
  location  = {Nara, Japan},
  series    = {ICFP 2016}
}

@article{DBLP:journals/corr/SeidelJW16,
  author        = {Eric L. Seidel and
                   Ranjit Jhala and
                   Ranjit Jhala and
                   Westley Weimer},
  title         = {Dynamic Witnesses for Static Type Errors},
  journal       = {CoRR},
  volume        = {abs/1606.07557},
  year          = {2016},
  url           = {http://arxiv.org/abs/1606.07557},
  archiveprefix = {arXiv},
  eprint        = {1606.07557},
  timestamp     = {Mon, 13 Aug 2018 16:46:09 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/SeidelJW16.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{10.1007/978-3-662-46669-8_33,
  author    = {Seidel, Eric L.
               and Vazou, Niki
               and Jhala, Ranjit},
  editor    = {Vitek, Jan},
  title     = {Type Targeted Testing},
  booktitle = {Programming Languages and Systems},
  year      = {2015},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {812--836},
  abstract  = {We present a new technique called type targeted testing, which translates precise refinement types into comprehensive test-suites. The key insight behind our approach is that through the lens of SMT solvers, refinement types can also be viewed as a high-level, declarative, test generation technique, wherein types are converted to SMT queries whose models can be decoded into concrete program inputs. Our approach enables the systematic and exhaustive testing of implementations from high-level declarative specifications, and furthermore, provides a gradual path from testing to full verification. We have implemented our approach as a Haskell testing tool called TARGET, and present an evaluation that shows how TARGET can be used to test a wide variety of properties and how it compares against state-of-the-art testing approaches.},
  isbn      = {978-3-662-46669-8}
}

@inproceedings{10.1145/2535838.2535863,
  author    = {Chen, Sheng and Erwig, Martin},
  title     = {Counter-Factual Typing for Debugging Type Errors},
  year      = {2014},
  isbn      = {9781450325448},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/2535838.2535863},
  abstract  = {Changing a program in response to a type error plays an important part in modern software development. However, the generation of good type error messages remains a problem for highly expressive type systems. Existing approaches often suffer from a lack of precision in locating errors and proposing remedies. Specifically, they either fail to locate the source of the type error consistently, or they report too many potential error locations. Moreover, the change suggestions offered are often incorrect. This makes the debugging process tedious and ineffective.We present an approach to the problem of type debugging that is based on generating and filtering a comprehensive set of type-change suggestions. Specifically, we generate all (program-structure-preserving) type changes that can possibly fix the type error. These suggestions will be ranked and presented to the programmer in an iterative fashion. In some cases we also produce suggestions to change the program. In most situations, this strategy delivers the correct change suggestions quickly, and at the same time never misses any rare suggestions. The computation of the potentially huge set of type-change suggestions is efficient since it is based on a variational type inference algorithm that type checks a program with variations only once, efficiently reusing type information for shared parts.We have evaluated our method and compared it with previous approaches. Based on a large set of examples drawn from the literature, we have found that our method outperforms other approaches and provides a viable alternative.},
  booktitle = {Proceedings of the 41st ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
  pages     = {583-594},
  numpages  = {12},
  keywords  = {type error messages, change suggestions, type inference, choice types, type-error debugging, error localization},
  location  = {San Diego, California, USA},
  series    = {POPL '14}
}

@inproceedings{10.1145/3314221.3314618,
  author    = {Hallahan, William T. and Xue, Anton and Bland, Maxwell Troy and Jhala, Ranjit and Piskac, Ruzica},
  title     = {Lazy Counterfactual Symbolic Execution},
  year      = {2019},
  isbn      = {9781450367127},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3314221.3314618},
  doi       = {10.1145/3314221.3314618},
  abstract  = {We present counterfactual symbolic execution, a new approach that produces counterexamples that localize the causes of failure of static verification. First, we develop a notion of symbolic weak head normal form and use it to define lazy symbolic execution reduction rules for non-strict languages like Haskell. Second, we introduce counterfactual branching, a new method to identify places where verification fails due to imprecise specifications (as opposed to incorrect code). Third, we show how to use counterfactual symbolic execution to localize refinement type errors, by translating refinement types into assertions. We implement our approach in a new Haskell symbolic execution engine, G2, and evaluate it on a corpus of 7550 errors gathered from users of the LiquidHaskell refinement type system. We show that for 97.7% of these errors, G2 is able to quickly find counterexamples that show how the code or specifications must be fixed to enable verification.},
  booktitle = {Proceedings of the 40th ACM SIGPLAN Conference on Programming Language Design and Implementation},
  pages     = {411--424},
  numpages  = {14},
  keywords  = {symbolic execution, counterexamples, Haskell, counterfactual, lazy},
  location  = {Phoenix, AZ, USA},
  series    = {PLDI 2019}
}


@inproceedings{10.1145/3331545.3342590,
  author    = {Hallahan, William T. and Xue, Anton and Piskac, Ruzica},
  title     = {G2Q: Haskell Constraint Solving},
  year      = {2019},
  isbn      = {9781450368131},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3331545.3342590},
  doi       = {10.1145/3331545.3342590},
  abstract  = {Constraint solvers give programmers a useful interface to solve challenging constraints at runtime. In particular, SMT solvers have been used for a vast variety of different, useful applications, ranging from strengthening Haskell's type system to verifying network protocols. Unfortunately, interacting with constraint solvers directly from Haskell requires a great deal of manual effort. Data must be represented in and translated between two forms: that understood by Haskell, and that understood by the SMT solver. Such a translation is often done via printing and parsing text, meaning that any notion of type safety is lost. Furthermore, direct translations are rarely sufficient, as it typically takes many iterations on a design in order to get optimal -- or even acceptable -- performance from a SMT solver on large scale problems. This need for iteration complicates the translation issue: it is easy to introduce a runtime bug and frustrating to fix said bug. To address these problems, we introduce a new constraint solving library, G2Q. G2Q includes a quasiquoter that allows solving constraints written in Haskell itself, thus unifying data representation, ensuring correct typing, and simplifying development iteration. We describe the API to our library and its backend. Rather than a direct translation to SMT formulas, G2Q makes use of the G2 symbolic execution engine. This allows G2Q to solve problems that are out of scope when directly encoded as SMT formulas. Finally, we demonstrate the usability of G2Q via four example programs.},
  booktitle = {Proceedings of the 12th ACM SIGPLAN International Symposium on Haskell},
  pages     = {44--57},
  numpages  = {14},
  keywords  = {symbolic execution, Haskell, constraint programming, constraint solving},
  location  = {Berlin, Germany},
  series    = {Haskell 2019}
}

@article{10.1145/3158139,
  author     = {Nguyundefinedn, Ph\'{u}c C. and Gilray, Thomas and Tobin-Hochstadt, Sam and Van Horn, David},
  title      = {Soft Contract Verification for Higher-Order Stateful Programs},
  year       = {2017},
  issue_date = {January 2018},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {2},
  number     = {POPL},
  url        = {https://doi.org/10.1145/3158139},
  doi        = {10.1145/3158139},
  abstract   = {Software contracts allow programmers to state rich program properties using the full expressive power of an object language. However, since they are enforced at runtime, monitoring contracts imposes significant overhead and delays error discovery. So contract veri cation aims to guarantee all or most of these properties ahead of time, enabling valuable optimizations and yielding a more general assurance of correctness. Existing methods for static contract verification satisfy the needs of more restricted target languages, but fail to address the challenges unique to those conjoining untyped, dynamic programming, higher-order functions, modularity, and statefulness. Our approach tackles all these features at once, in the context of the full Racket system—a mature environment for stateful, higher-order, multi-paradigm programming with or with- out types. Evaluating our method using a set of both pure and stateful benchmarks, we are able to verify 99.94% of checks statically (all but 28 of 49, 861). Stateful, higher-order functions pose significant challenges for static contract verification in particular. In the presence of these features, a modular analysis must permit code from the current module to escape permanently to an opaque context (unspecified code from outside the current module) that may be stateful and therefore store a reference to the escaped closure. Also, contracts themselves, being predicates wri en in unrestricted Racket, may exhibit stateful behavior; a sound approach must be robust to contracts which are arbitrarily expressive and interwoven with the code they monitor. In this paper, we present and evaluate our solution based on higher-order symbolic execution, explain the techniques we used to address such thorny issues, formalize a notion of behavioral approximation, and use it to provide a mechanized proof of soundness.},
  journal    = {Proceedings of the ACM on Programming Languages},
  month      = dec,
  articleno  = {51},
  numpages   = {30},
  keywords   = {symbolic execution, Higher-order contracts}
}

@inproceedings{10.1007/978-3-642-23702-7_11,
  author    = {Ma, Kin-Keung
               and Yit Phang, Khoo
               and Foster, Jeffrey S.
               and Hicks, Michael},
  editor    = {Yahav, Eran},
  title     = {Directed Symbolic Execution},
  booktitle = {Static Analysis},
  year      = {2011},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {95--111},
  abstract  = {In this paper, we study the problem of automatically finding program executions that reach a particular target line. This problem arises in many debugging scenarios; for example, a developer may want to confirm that a bug reported by a static analysis tool on a particular line is a true positive. We propose two new directed symbolic execution strategies that aim to solve this problem: shortest-distance symbolic execution (SDSE) uses a distance metric in an interprocedural control flow graph to guide symbolic execution toward a particular target; and call-chain-backward symbolic execution (CCBSE) iteratively runs forward symbolic execution, starting in the function containing the target line, and then jumping backward up the call chain until it finds a feasible path from the start of the program. We also propose a hybrid strategy, Mix-CCBSE, which alternates CCBSE with another (forward) search strategy. We compare these three with several existing strategies from the literature on a suite of six GNU Coreutils programs. We find that SDSE performs extremely well in many cases but may fail badly. CCBSE also performs quite well, but imposes additional overhead that sometimes makes it slower than SDSE. Considering all our benchmarks together, Mix-CCBSE performed best on average, combining to good effect the features of its constituent components.},
  isbn      = {978-3-642-23702-7}
}

@inproceedings{10.1007/978-3-030-11245-5_11,
  author    = {Germane, Kimball
               and McCarthy, Jay
               and Adams, Michael D.
               and Might, Matthew},
  editor    = {Enea, Constantin
               and Piskac, Ruzica},
  title     = {Demand Control-Flow Analysis},
  booktitle = {Verification, Model Checking, and Abstract Interpretation},
  year      = {2019},
  publisher = {Springer International Publishing},
  address   = {Cham},
  pages     = {226--246},
  abstract  = {Points-to analysis manifests in a functional setting as control-flow analysis. Despite the ubiquity of demand points-to analyses, there are no analogous demand control-flow analyses for functional languages in general. We present demand 0CFA, a demand control-flow analysis that offers clients in a functional setting the same pricing model that demand points-to analysis clients enjoy in an imperative setting. We establish demand 0CFA's correctness via an intermediary exact semantics, demand evaluation, that can potentially support demand variants of more-precise analyses.},
  isbn      = {978-3-030-11245-5}
}

@inproceedings{palmer_et_al:LIPIcs:2016:6113,
  author    = {Zachary Palmer and Scott F. Smith},
  title     = {{Higher-Order Demand-Driven Program Analysis}},
  booktitle = {30th European Conference on Object-Oriented Programming (ECOOP 2016)},
  pages     = {19:1--19:25},
  series    = {Leibniz International Proceedings in Informatics (LIPIcs)},
  isbn      = {978-3-95977-014-9},
  issn      = {1868-8969},
  year      = {2016},
  volume    = {56},
  editor    = {Shriram Krishnamurthi and Benjamin S. Lerner},
  publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
  address   = {Dagstuhl, Germany},
  url       = {http://drops.dagstuhl.de/opus/volltexte/2016/6113},
  urn       = {urn:nbn:de:0030-drops-61132},
  doi       = {10.4230/LIPIcs.ECOOP.2016.19},
  annote    = {Keywords: functional programming, program analysis, polynomial-time, demand-driven, flow-sensitive, context-sensitive}
}


@article{10.1145/2408776.2408795,
  author     = {Cadar, Cristian and Sen, Koushik},
  title      = {Symbolic Execution for Software Testing: Three Decades Later},
  year       = {2013},
  issue_date = {February 2013},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {56},
  number     = {2},
  issn       = {0001-0782},
  url        = {https://doi.org/10.1145/2408776.2408795},
  doi        = {10.1145/2408776.2408795},
  abstract   = {The challenges---and great promise---of modern symbolic execution techniques, and the tools to help implement them.},
  journal    = {Commun. ACM},
  month      = feb,
  pages      = {82--90},
  numpages   = {9}
}

@inproceedings{10.1145/2951913.2951933,
  author    = {Dagand, Pierre-Evariste and Tabareau, Nicolas and Tanter, \'{E}ric},
  title     = {Partial Type Equivalences for Verified Dependent Interoperability},
  year      = {2016},
  isbn      = {9781450342193},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/2951913.2951933},
  doi       = {10.1145/2951913.2951933},
  abstract  = { Full-spectrum dependent types promise to enable the development of correct-by-construction software. However, even certified software needs to interact with simply-typed or untyped programs, be it to perform system calls, or to use legacy libraries. Trading static guarantees for runtime checks, the dependent interoperability framework provides a mechanism by which simply-typed values can safely be coerced to dependent types and, conversely, dependently-typed programs can defensively be exported to a simply-typed application. In this paper, we give a semantic account of dependent interoperability. Our presentation relies on and is guided by a pervading notion of type equivalence, whose importance has been emphasized in recent work on homotopy type theory. Specifically, we develop the notion of partial type equivalences as a key foundation for dependent interoperability. Our framework is developed in Coq; it is thus constructive and verified in the strictest sense of the terms. Using our library, users can specify domain-specific partial equivalences between data structures. Our library then takes care of the (sometimes, heavy) lifting that leads to interoperable programs. It thus becomes possible, as we shall illustrate, to internalize and hand-tune the extraction of dependently-typed programs to interoperable OCaml programs within Coq itself. },
  booktitle = {Proceedings of the 21st ACM SIGPLAN International Conference on Functional Programming},
  pages     = {298–310},
  numpages  = {13},
  keywords  = {type equivalences, interoperability, dependent types},
  location  = {Nara, Japan},
  series    = {ICFP 2016}
}


@article{10.1145/3022670.2951933,
  author     = {Dagand, Pierre-Evariste and Tabareau, Nicolas and Tanter, \'{E}ric},
  title      = {Partial Type Equivalences for Verified Dependent Interoperability},
  year       = {2016},
  issue_date = {September 2016},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {51},
  number     = {9},
  issn       = {0362-1340},
  url        = {https://doi.org/10.1145/3022670.2951933},
  doi        = {10.1145/3022670.2951933},
  abstract   = { Full-spectrum dependent types promise to enable the development of correct-by-construction software. However, even certified software needs to interact with simply-typed or untyped programs, be it to perform system calls, or to use legacy libraries. Trading static guarantees for runtime checks, the dependent interoperability framework provides a mechanism by which simply-typed values can safely be coerced to dependent types and, conversely, dependently-typed programs can defensively be exported to a simply-typed application. In this paper, we give a semantic account of dependent interoperability. Our presentation relies on and is guided by a pervading notion of type equivalence, whose importance has been emphasized in recent work on homotopy type theory. Specifically, we develop the notion of partial type equivalences as a key foundation for dependent interoperability. Our framework is developed in Coq; it is thus constructive and verified in the strictest sense of the terms. Using our library, users can specify domain-specific partial equivalences between data structures. Our library then takes care of the (sometimes, heavy) lifting that leads to interoperable programs. It thus becomes possible, as we shall illustrate, to internalize and hand-tune the extraction of dependently-typed programs to interoperable OCaml programs within Coq itself. },
  journal    = {ACM SIGPLAN Notices},
  month      = sep,
  pages      = {298--310},
  numpages   = {13},
  keywords   = {type equivalences, interoperability, dependent types}
}

@inproceedings{10.1007/1-4020-8141-3_34,
  author    = {Ou, Xinming
               and Tan, Gang
               and Mandelbaum, Yitzhak
               and Walker, David},
  editor    = {Levy, Jean-Jacques
               and Mayr, Ernst W.
               and Mitchell, John C.},
  title     = {Dynamic Typing with Dependent Types},
  booktitle = {Exploring New Frontiers of Theoretical Informatics},
  year      = {2004},
  publisher = {Springer US},
  address   = {Boston, MA},
  pages     = {437--450},
  abstract  = {Dependent type systems are promising tools programmers can use to increase the reliability and security of their programs. Unfortunately, dependently-typed programming languages require programmers to annotate their programs with many typing specifications to help guide the type checker. This paper shows how to make the process of programming with dependent types more palatable by defining a language in which programmers have fine-grained control over the trade-off between the number of dependent typing annotations they must place on programs and the degree of compile-time safety. More specifically, certain program fragments are marked dependent, in which case the programmer annotates them in detail and a dependent type checker verifies them at compile time. Other fragments are marked simple, in which case they may be annotation-free and dependent constraints are verified at run time.},
  isbn      = {978-1-4020-8141-5}
}

@inproceedings{10.1145/2816707.2816710,
  author    = {Tanter, \'{E}ric and Tabareau, Nicolas},
  title     = {Gradual Certified Programming in Coq},
  year      = {2015},
  isbn      = {9781450336901},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/2816707.2816710},
  abstract  = { Expressive static typing disciplines are a powerful way to achieve high-quality software. However, the adoption cost of such techniques should not be under-estimated. Just like gradual typing allows for a smooth transition from dynamically-typed to statically-typed programs, it seems desirable to support a gradual path to certified programming. We explore gradual certified programming in Coq, providing the possibility to postpone the proofs of selected properties, and to check "at runtime" whether the properties actually hold. Casts can be integrated with the implicit coercion mechanism of Coq to support implicit cast insertion \`{a} la gradual typing. Additionally, when extracting Coq functions to mainstream languages, our encoding of casts supports lifting assumed properties into runtime checks. Much to our surprise, it is not necessary to extend Coq in any way to support gradual certified programming. A simple mix of type classes and axioms makes it possible to bring gradual certified programming to Coq in a straightforward manner. },
  booktitle = {Proceedings of the 11th Symposium on Dynamic Languages},
  pages     = {26–40},
  numpages  = {15},
  keywords  = {subset types, Coq, program extraction, casts, Certified programming, refinements, gradual typing},
  location  = {Pittsburgh, PA, USA},
  series    = {DLS 2015}
}


@article{10.1145/2936313.2816710,
  author     = {Tanter, \'{E}ric and Tabareau, Nicolas},
  title      = {Gradual Certified Programming in Coq},
  year       = {2015},
  issue_date = {Feburary 2016},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {51},
  number     = {2},
  issn       = {0362-1340},
  doi        = {10.1145/2936313.2816710},
  abstract   = { Expressive static typing disciplines are a powerful way to achieve high-quality software. However, the adoption cost of such techniques should not be under-estimated. Just like gradual typing allows for a smooth transition from dynamically-typed to statically-typed programs, it seems desirable to support a gradual path to certified programming. We explore gradual certified programming in Coq, providing the possibility to postpone the proofs of selected properties, and to check "at runtime" whether the properties actually hold. Casts can be integrated with the implicit coercion mechanism of Coq to support implicit cast insertion \`{a} la gradual typing. Additionally, when extracting Coq functions to mainstream languages, our encoding of casts supports lifting assumed properties into runtime checks. Much to our surprise, it is not necessary to extend Coq in any way to support gradual certified programming. A simple mix of type classes and axioms makes it possible to bring gradual certified programming to Coq in a straightforward manner. },
  journal    = {ACM SIGPLAN Notices},
  month      = oct,
  pages      = {26--40},
  numpages   = {15},
  keywords   = {subset types, Coq, refinements, program extraction, gradual typing, casts, Certified programming}
}

@article{dagand_tabareau_tanter_2018,
  title     = {Foundations of dependent interoperability},
  volume    = {28},
  doi       = {10.1017/S0956796818000011},
  journal   = {Journal of Functional Programming},
  publisher = {Cambridge University Press},
  author    = {Dagand, Pierre-Evariste and Tabareau, Nicolas and Tanter, {\'E}ric},
  year      = {2018},
  pages     = {e9}
}

@article{dagandtype,
  title  = {Type-Theoretic Galois Connections},
  author = {Dagand, Pierre-{\'E}variste and Tabareau, Nicolas and Tanter, {\'E}ric}
}


@unpublished{bertrand:hal-02896776,
  title       = {Gradualizing the Calculus of Inductive Constructions},
  author      = {Bertrand, Meven and Maillard, Kenji and Tabareau, Nicolas and Tanter, {\'E}ric},
  url         = {https://hal.archives-ouvertes.fr/hal-02896776},
  note        = {working paper or preprint},
  year        = {2020},
  month       = Jul,
  pdf         = {https://hal.archives-ouvertes.fr/hal-02896776/file/main.pdf},
  hal_id      = {hal-02896776},
  hal_version = {v1}
}

@article{10.1145/3495528,
  author     = {Lennon-Bertrand, Meven and Maillard, Kenji and Tabareau, Nicolas and Tanter, \'{E}ric},
  title      = {Gradualizing the Calculus of Inductive Constructions},
  year       = {2022},
  issue_date = {June 2022},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {44},
  number     = {2},
  issn       = {0164-0925},
  url        = {https://doi.org/10.1145/3495528},
  doi        = {10.1145/3495528},
  abstract   = {We investigate gradual variations on the Calculus of Inductive Construction (CIC) for swifter prototyping with imprecise types and terms. We observe, with a no-go theorem, a crucial trade-off between graduality and the key properties of normalization and closure of universes under dependent product that CIC enjoys. Beyond this Fire Triangle of Graduality, we explore the gradualization of CIC with three different compromises, each relaxing one edge of the Fire Triangle. We develop a parametrized presentation of Gradual CIC (GCIC) that encompasses all three variations, and develop their metatheory. We first present a bidirectional elaboration of GCIC to a dependently-typed cast calculus, CastCIC, which elucidates the interrelation between typing, conversion, and the gradual guarantees. We use a syntactic model of CastCIC to inform the design of a safe, confluent reduction, and establish, when applicable, normalization. We study the static and dynamic gradual guarantees as well as the stronger notion of graduality with embedding-projection pairs formulated by New and Ahmed, using appropriate semantic model constructions. This work informs and paves the way towards the development of malleable proof assistants and dependently-typed programming languages.},
  journal    = {ACM Transactions on Programming Languages and Systems},
  month      = {apr},
  articleno  = {7},
  numpages   = {82},
  keywords   = {Gradual typing, dependent types, proof assistants}
}


@inproceedings{10.1007/978-3-642-00590-9_1,
  author    = {Wadler, Philip
               and Findler, Robert Bruce},
  editor    = {Castagna, Giuseppe},
  title     = {Well-Typed Programs Can't Be Blamed},
  booktitle = {Programming Languages and Systems},
  year      = {2009},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {1--16},
  abstract  = {We introduce the blame calculus, which adds the notion of blame from Findler and Felleisen's contracts to a system similar to Siek and Taha's gradual types and Flanagan's hybrid types. We characterise where positive and negative blame can arise by decomposing the usual notion of subtype into positive and negative subtypes, and show that these recombine to yield naive subtypes. Naive subtypes previously appeared in type systems that are unsound, but we believe this is the first time naive subtypes play a role in establishing type soundness.},
  isbn      = {978-3-642-00590-9}
}


@article{10.1145/1330017.1330019,
  author     = {Weimer, Westley and Necula, George C.},
  title      = {Exceptional Situations and Program Reliability},
  year       = {2008},
  issue_date = {March 2008},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {30},
  number     = {2},
  issn       = {0164-0925},
  doi        = {10.1145/1330017.1330019},
  abstract   = {It is difficult to write programs that behave correctly in the presence of run-time errors. Proper behavior in the face of exceptional situations is important to the reliability of long-running programs. Existing programming language features often provide poor support for executing clean-up code and for restoring invariants.We present a data-flow analysis for finding a certain class of exception-handling defects: those related to a failure to release resources or to clean up properly along all paths. Many real-world programs violate such resource usage rules because of incorrect exception handling. Our flow-sensitive analysis keeps track of outstanding obligations along program paths and does a precise modeling of control flow in the presence of exceptions. Using it, we have found over 1,300 exception handling defects in over 5 million lines of Java code.Based on those defects we propose a programming language feature, the compensation stack, that keeps track of obligations at run time and ensures that they are discharged. We present a type system for compensation stacks that tracks collections of obligations. Finally, we present case studies to demonstrate that this feature is natural, efficient, and can improve reliability.},
  journal    = {ACM Transactions on Programming Languages and Systems},
  month      = mar,
  articleno  = {8},
  numpages   = {51},
  keywords   = {linear types, linear sagas, compensating transactions, Error handling, resource management}
}

@inproceedings{wadler:LIPIcs:2015:5033,
  author    = {Philip Wadler},
  title     = {{A Complement to Blame}},
  booktitle = {1st Summit on Advances in Programming Languages (SNAPL 2015)},
  pages     = {309--320},
  series    = {Leibniz International Proceedings in Informatics (LIPIcs)},
  isbn      = {978-3-939897-80-4},
  issn      = {1868-8969},
  year      = {2015},
  volume    = {32},
  editor    = {Thomas Ball and Rastislav Bodik and Shriram Krishnamurthi and Benjamin S. Lerner and Greg Morrisett},
  publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
  address   = {Dagstuhl, Germany},
  url       = {http://drops.dagstuhl.de/opus/volltexte/2015/5033},
  urn       = {urn:nbn:de:0030-drops-50333},
  doi       = {10.4230/LIPIcs.SNAPL.2015.309},
  annote    = {Keywords: contracts, gradual typing, hybrid typing, blame calculus}
}


@inproceedings{10.1145/1111037.1111059,
  author    = {Flanagan, Cormac},
  title     = {Hybrid Type Checking},
  year      = {2006},
  isbn      = {1595930272},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/1111037.1111059},
  abstract  = {Traditional static type systems are very effective for verifying basic interface specifications, but are somewhat limited in the kinds specifications they support. Dynamically-checked contracts can enforce more precise specifications, but these are not checked until run time, resulting in incomplete detection of defects.Hybrid type checking is a synthesis of these two approaches that enforces precise interface specifications, via static analysis where possible, but also via dynamic checks where necessary. This paper explores the key ideas and implications of hybrid type checking, in the context of the simply-typed λ-calculus with arbitrary refinements of base types.},
  booktitle = acm-popl,
  pages     = {245--256},
  numpages  = {12},
  keywords  = {dynamic checking, contracts, type systems, static checking},
  location  = {Charleston, South Carolina, USA},
  series    = {POPL '06}
}


@article{10.1145/1111320.1111059,
  author     = {Flanagan, Cormac},
  title      = {Hybrid Type Checking},
  year       = {2006},
  issue_date = {January 2006},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {41},
  number     = {1},
  issn       = {0362-1340},
  doi        = {10.1145/1111320.1111059},
  abstract   = {Traditional static type systems are very effective for verifying basic interface specifications, but are somewhat limited in the kinds specifications they support. Dynamically-checked contracts can enforce more precise specifications, but these are not checked until run time, resulting in incomplete detection of defects.Hybrid type checking is a synthesis of these two approaches that enforces precise interface specifications, via static analysis where possible, but also via dynamic checks where necessary. This paper explores the key ideas and implications of hybrid type checking, in the context of the simply-typed λ-calculus with arbitrary refinements of base types.},
  journal    = {ACM SIGPLAN Notices},
  month      = jan,
  pages      = {245--256},
  numpages   = {12},
  keywords   = {type systems, static checking, contracts, dynamic checking}
}

@article{10.1145/1667048.1667051,
  author     = {Knowles, Kenneth and Flanagan, Cormac},
  title      = {Hybrid Type Checking},
  year       = {2010},
  issue_date = {January 2010},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {32},
  number     = {2},
  issn       = {0164-0925},
  url        = {https://doi.org/10.1145/1667048.1667051},
  doi        = {10.1145/1667048.1667051},
  abstract   = {Traditional static type systems are effective for verifying basic interface specifications. Dynamically checked contracts support more precise specifications, but these are not checked until runtime, resulting in incomplete detection of defects. Hybrid type checking is a synthesis of these two approaches that enforces precise interface specifications, via static analysis where possible, but also via dynamic checks where necessary. This article explores the key ideas and implications of hybrid type checking, in the context of the λ-calculus extended with contract types, that is, with dependent function types and with arbitrary refinements of base types.},
  journal    = {ACM Transactions on Programming Languages and Systems},
  month      = {feb},
  articleno  = {6},
  numpages   = {34},
  keywords   = {Type systems, contracts, dynamic checking, static checking}
}

@article{10.1145/2398856.2364554,
  author     = {Vytiniotis, Dimitrios and Peyton Jones, Simon and Magalh\~{a}es, Jos\'{e} Pedro},
  title      = {Equality Proofs and Deferred Type Errors: A Compiler Pearl},
  year       = {2012},
  issue_date = {September 2012},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {47},
  number     = {9},
  issn       = {0362-1340},
  url        = {https://doi.org/10.1145/2398856.2364554},
  doi        = {10.1145/2398856.2364554},
  abstract   = {The Glasgow Haskell Compiler is an optimizing compiler that expresses and manipulates first-class equality proofs in its intermediate language. We describe a simple, elegant technique that exploits these equality proofs to support deferred type errors. The technique requires us to treat equality proofs as possibly-divergent terms; we show how to do so without losing either soundness or the zero-overhead cost model that the programmer expects.},
  journal    = {SIGPLAN Notices},
  month      = {sep},
  pages      = {341–352},
  numpages   = {12},
  keywords   = {deferred type errors, system fc, type equalities}
}


@inproceedings{10.1145/2364527.2364554,
  author    = {Vytiniotis, Dimitrios and Peyton Jones, Simon and Magalh\~{a}es, Jos\'{e} Pedro},
  title     = {Equality Proofs and Deferred Type Errors: A Compiler Pearl},
  year      = {2012},
  isbn      = {9781450310543},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/2364527.2364554},
  doi       = {10.1145/2364527.2364554},
  abstract  = {The Glasgow Haskell Compiler is an optimizing compiler that expresses and manipulates first-class equality proofs in its intermediate language. We describe a simple, elegant technique that exploits these equality proofs to support deferred type errors. The technique requires us to treat equality proofs as possibly-divergent terms; we show how to do so without losing either soundness or the zero-overhead cost model that the programmer expects.},
  booktitle = {Proceedings of the 17th ACM SIGPLAN International Conference on Functional Programming},
  pages     = {341–352},
  numpages  = {12},
  keywords  = {deferred type errors, type equalities, system fc},
  location  = {Copenhagen, Denmark},
  series    = {ICFP '12}
}



@article{10.1145/3341692,
  author     = {Eremondi, Joseph and Tanter, \'{E}ric and Garcia, Ronald},
  title      = {Approximate Normalization for Gradual Dependent Types},
  year       = {2019},
  issue_date = {August 2019},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {3},
  url        = {https://doi.org/10.1145/3341692},
  doi        = {10.1145/3341692},
  abstract   = {Dependent types help programmers write highly reliable code. However, this reliability comes at a cost: it can be challenging to write new prototypes in (or migrate old code to) dependently-typed programming languages. Gradual typing makes static type disciplines more flexible, so an appropriate notion of gradual dependent types could fruitfully lower this cost. However, dependent types raise unique challenges for gradual typing. Dependent typechecking involves the execution of program code, but gradually-typed code can signal runtime type errors or diverge. These runtime errors threaten the soundness guarantees that make dependent types so attractive, while divergence spoils the type-driven programming experience. This paper presents GDTL, a gradual dependently-typed language that emphasizes pragmatic dependently-typed programming. GDTL fully embeds both an untyped and dependently-typed language, and allows for smooth transitions between the two. In addition to gradual types we introduce gradual terms, which allow the user to be imprecise in type indices and to omit proof terms; runtime checks ensure type safety. To account for nontermination and failure, we distinguish between compile-time normalization and run-time execution: compile-time normalization is approximate but total, while runtime execution is exact, but may fail or diverge. We prove that GDTL has decidable typechecking and satisfies all the expected properties of gradual languages. In particular, GDTL satisfies the static and dynamic gradual guarantees: reducing type precision preserves typedness, and altering type precision does not change program behavior outside of dynamic type failures. To prove these properties, we were led to establish a novel normalization gradual guarantee that captures the monotonicity of approximate normalization with respect to imprecision.},
  journal    = {Proceedings of the ACM on Programming Languages},
  month      = jul,
  articleno  = {88},
  numpages   = {30},
  keywords   = {dependent types, normalization, Gradual types}
}

@inproceedings{siek_et_al:LIPIcs:2015:5031,
  author    = {Jeremy G. Siek and Michael M. Vitousek and Matteo Cimini and John Tang Boyland},
  title     = {{Refined Criteria for Gradual Typing}},
  booktitle = {1st Summit on Advances in Programming Languages (SNAPL 2015)},
  pages     = {274--293},
  series    = {Leibniz International Proceedings in Informatics (LIPIcs)},
  isbn      = {978-3-939897-80-4},
  issn      = {1868-8969},
  year      = {2015},
  volume    = {32},
  editor    = {Thomas Ball and Rastislav Bodik and Shriram Krishnamurthi and Benjamin S. Lerner and Greg Morrisett},
  publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
  address   = {Dagstuhl, Germany},
  url       = {http://drops.dagstuhl.de/opus/volltexte/2015/5031},
  urn       = {urn:nbn:de:0030-drops-50312},
  doi       = {10.4230/LIPIcs.SNAPL.2015.274},
  annote    = {Keywords: gradual typing, type systems, semantics, dynamic languages}
}

@article{DBLP:journals/corr/abs-1906-06469,
  author        = {Joseph Eremondi and
                   {\'{E}}ric Tanter and
                   Ronald Garcia},
  title         = {Approximate Normalization for Gradual Dependent Types},
  journal       = {CoRR},
  volume        = {abs/1906.06469},
  year          = {2019},
  url           = {http://arxiv.org/abs/1906.06469},
  archiveprefix = {arXiv},
  eprint        = {1906.06469},
  timestamp     = {Mon, 24 Jun 2019 17:28:45 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1906-06469.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{10.1145/2837614.2837670,
  author    = {Garcia, Ronald and Clark, Alison M. and Tanter, \'{E}ric},
  title     = {Abstracting Gradual Typing},
  year      = {2016},
  isbn      = {9781450335492},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/2837614.2837670},
  doi       = {10.1145/2837614.2837670},
  abstract  = { Language researchers and designers have extended a wide variety of type systems to support gradual typing, which enables languages to seamlessly combine dynamic and static checking. These efforts consistently demonstrate that designing a satisfactory gradual counterpart to a static type system is challenging, and this challenge only increases with the sophistication of the type system. Gradual type system designers need more formal tools to help them conceptualize, structure, and evaluate their designs. In this paper, we propose a new formal foundation for gradual typing, drawing on principles from abstract interpretation to give gradual types a semantics in terms of pre-existing static types. Abstracting Gradual Typing (AGT for short) yields a formal account of consistency---one of the cornerstones of the gradual typing approach---that subsumes existing notions of consistency, which were developed through intuition and ad hoc reasoning. Given a syntax-directed static typing judgment, the AGT approach induces a corresponding gradual typing judgment. Then the type safety proof for the underlying static discipline induces a dynamic semantics for gradual programs defined over source-language typing derivations. The AGT approach does not resort to an externally justified cast calculus: instead, run-time checks naturally arise by deducing evidence for consistent judgments during proof reduction. To illustrate the approach, we develop a novel gradually-typed counterpart for a language with record subtyping. Gradual languages designed with the AGT approach satisfy by construction the refined criteria for gradual typing set forth by Siek and colleagues. },
  booktitle = acm-popl,
  pages     = {429--442},
  numpages  = {14},
  keywords  = {abstract interpretation, subtyping, gradual typing},
  location  = {St. Petersburg, FL, USA},
  series    = {POPL '16}
}


@article{10.1145/291251.289451,
  author     = {Augustsson, Lennart},
  title      = {Cayenne—a Language with Dependent Types},
  year       = {1998},
  issue_date = {Jan. 1999},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {34},
  number     = {1},
  issn       = {0362-1340},
  doi        = {10.1145/291251.289451},
  abstract   = {Cayenne is a Haskell-like language. The main difference between Haskell and Cayenne is that Cayenne has dependent types, i.e., the result type of a function may depend on the argument value, and types of record components (which can be types or values) may depend on other components. Cayenne also combines the syntactic categories for value expressions and type expressions; thus reducing the number of language concepts.Having dependent types and combined type and value expressions makes the language very powerful. It is powerful enough that a special module concept is unnecessary; ordinary records suffice. It is also powerful enough to encode predicate logic at the type level, allowing types to be used as specifications of programs. However, this power comes at a cost: type checking of Cayenne is undecidable. While this may appear to be a steep price to pay, it seems to work well in practice.},
  journal    = {ACM SIGPLAN Notices},
  month      = sep,
  pages      = {239–250},
  numpages   = {12},
  keywords   = {type systems, module systems, language design, dependent types}
}


@inproceedings{10.1145/289423.289451,
  author    = {Augustsson, Lennart},
  title     = {Cayenne a language with dependent types},
  year      = {1998},
  isbn      = {1581130244},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/289423.289451},
  abstract  = {Cayenne is a Haskell-like language. The main difference between Haskell and Cayenne is that Cayenne has dependent types, i.e., the result type of a function may depend on the argument value, and types of record components (which can be types or values) may depend on other components. Cayenne also combines the syntactic categories for value expressions and type expressions; thus reducing the number of language concepts.Having dependent types and combined type and value expressions makes the language very powerful. It is powerful enough that a special module concept is unnecessary; ordinary records suffice. It is also powerful enough to encode predicate logic at the type level, allowing types to be used as specifications of programs. However, this power comes at a cost: type checking of Cayenne is undecidable. While this may appear to be a steep price to pay, it seems to work well in practice.},
  booktitle = {Proceedings of the Third ACM SIGPLAN International Conference on Functional Programming},
  pages     = {239--250},
  numpages  = {12},
  keywords  = {dependent types, language design, module systems, type systems},
  location  = {Baltimore, Maryland, USA},
  series    = {ICFP '98}
}

@inproceedings{c4be73a0daf74c9aa4d13483a2c4dd0e,
  title     = {$\lambda$dB: Blame tracking at higher fidelity},
  abstract  = {This paper introduces λdB, a blame calculus with dependent types. It supports dependent functions, predicate refinement at all types, the dynamic type, and full blame tracking. It is inspired by and extends previous work on hybrid types and Sage, by Flanagan and others; manifest contracts, by Greenberg, Pierce, and Weirich; and blame calculus by Wadler and Findler. While previous work only allows refinement over base types, λdB supports refinement over any type. We introduce novel techniques in order to prove blame safety for this language, including a careful analysis that reduces open judgments on terms to closed ones on values, and the idea of {\textquoteleft}subtyping with a witness{\textquoteright}, which fix flaws in the previous work of Wadler and Findler. These technical contributions mean that we can achieve a completely operational account of the metatheory of our language, and thereby avoid the need to intertwine operational and semantic models which bedevils the work on hybrid types and manifest contracts.},
  author    = {Jakub Zalewski and James McKinna and Morris, {J. Garrett} and Philip Wadler},
  year      = {2020},
  month     = {January},
  language  = {English},
  series    = {WGT20},
  address   = {New Orleans},
  booktitle = {Workshop on Gradual Typing},
  pages     = {171--192},
  publisher = {Association for Computing Machinery}
}


@article{10.1145/1111320.1111038,
  author     = {McKinna, James},
  title      = {Why Dependent Types Matter},
  year       = {2006},
  issue_date = {January 2006},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {41},
  number     = {1},
  issn       = {0362-1340},
  doi        = {10.1145/1111320.1111038},
  abstract   = {Language designers have in recent years proposed a wealth of richer type systems for programming which seek to extend the range of statically enforced guarantees on data and code. Most such proposals have been evolutionary extensions of ML or Haskell, offering programmers a balanced compromise between expressive strength and existing well-understood technology. Typically they revolve around type- or kind-indexed types such as GADTs, supported by limited equality reasoning at the type-checking level, thus separating the dynamic behaviour of programs from the (simpler) static behaviour of indexing information occurring in their types.I want to argue in this talk for a more radical departure from such practice by examining full spectrum type dependency, lifting such restrictions on the data upon which types may depend. Conor McBride and I designed the language EPIGRAM for experiments in programming with inductive families of data (of which GADTs are a special case). Using it for illustration, I will explore some of the possibilities and challenges afforded by full spectrum type dependency at the static and dynamic level: types directly support modelling complex invariants in terms of other data (rather than their types), with a Curry-Howard flavour of data-as-evidence; such complexity is on a 'pay-as-you-go' basis, while keeping type annotations and other syntactic overheads to a minimum;data decomposition steps, e.g. case analysis, furnish more informative interactions between types and values during typechecking; such steps may moreover be abstractly specified by their types, and thus user definable; this supports a style of programming embracing 'learning by testing', views, and Burstall's 'hand simulation plus a little induction';the absence of a rigid phase distinction need not lead to type-passing or excessive run-time overhead; effectful computation, in particular partiality, can be incorporated via variations on existing ideas such as monads.This talk is based on joint work with Conor McBride, Edwin Brady and Thorsten Altenkirch.},
  journal    = {ACM SIGPLAN Notices},
  month      = jan,
  pages      = {1},
  numpages   = {1}
}

@inproceedings{sterling_et_al:LIPIcs:2019:10538,
  author    = {Jonathan Sterling and Carlo Angiuli and Daniel Gratzer},
  title     = {{Cubical Syntax for Reflection-Free Extensional Equality}},
  booktitle = {4th International Conference on Formal Structures for Computation and Deduction (FSCD 2019)},
  pages     = {31:1--31:25},
  series    = {Leibniz International Proceedings in Informatics (LIPIcs)},
  isbn      = {978-3-95977-107-8},
  issn      = {1868-8969},
  year      = {2019},
  volume    = {131},
  editor    = {Herman Geuvers},
  publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
  address   = {Dagstuhl, Germany},
  url       = {http://drops.dagstuhl.de/opus/volltexte/2019/10538},
  urn       = {urn:nbn:de:0030-drops-105387},
  doi       = {10.4230/LIPIcs.FSCD.2019.31},
  annote    = {Keywords: Dependent type theory, extensional equality, cubical type theory, categorical gluing, canonicity}
}

@book{brady2017type,
  title     = {Type-driven development with Idris},
  author    = {Brady, Edwin},
  year      = {2017},
  publisher = {Manning Publications Company}
}

@article{bradyidris,
  title  = {Idris 2: Quantitative Type Theory in Action},
  author = {Brady, Edwin}
}

@inproceedings{cockx2021taming,
  title     = {The Taming of the Rew: A Type Theory with Computational Assumptions},
  author    = {Cockx, Jesper and Tabareau, Nicolas and Winterhalter, Th{\'e}o},
  booktitle = acm-popl,
  year      = {2021}
}

@article{KOKKE2020102440,
  title    = {Programming language foundations in Agda},
  journal  = {Science of Computer Programming},
  volume   = {194},
  pages    = {102440},
  year     = {2020},
  issn     = {0167-6423},
  doi      = {https://doi.org/10.1016/j.scico.2020.102440},
  url      = {http://www.sciencedirect.com/science/article/pii/S0167642320300502},
  author   = {Wen Kokke and Jeremy G. Siek and Philip Wadler},
  keywords = {Agda, Coq, Lambda calculus, Dependent types},
  abstract = {One of the leading textbooks for formal methods is Software Foundations (SF), written by Benjamin Pierce in collaboration with others, and based on Coq. After five years using SF in the classroom, we came to the conclusion that Coq is not the best vehicle for this purpose, as too much of the course needs to focus on learning tactics for proof derivation, to the cost of learning programming language theory. Accordingly, we have written a new textbook, Programming Language Foundations in Agda (PLFA). PLFA covers much of the same ground as SF, although it is not a slavish imitation. What did we learn from writing PLFA? First, that it is possible. One might expect that without proof tactics that the proofs become too long, but in fact proofs in PLFA are about the same length as those in SF. Proofs in Coq require an interactive environment to be understood, while proofs in Agda can be read on the page. Second, that constructive proofs of preservation and progress give immediate rise to a prototype evaluator. This fact is obvious in retrospect but it is not exploited in SF (which instead provides a separate normalise tactic) nor can we find it in the literature. Third, that using extrinsically-typed terms is far less perspicuous than using intrinsically-typed terms. SF uses the former presentation, while PLFA presents both; the former uses about 1.6 as many lines of Agda code as the latter, roughly the golden ratio. The textbook is written as a literate Agda script, and can be found here: http://plfa.inf.ed.ac.uk}
}

@techreport{knowles2008compositional,
  title   = {Compositional and Decidable Checking for Dependent Contract Types},
  author  = {Knowles, Kenneth and Flanagan, Cormac},
  journal = {Contract},
  pages   = {1--11},
  year    = {2008}
}

@inproceedings{10.1145/1481848.1481853,
author = {Knowles, Kenneth and Flanagan, Cormac},
title = {Compositional Reasoning and Decidable Checking for Dependent Contract Types},
year = {2009},
isbn = {9781605583303},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1481848.1481853},
doi = {10.1145/1481848.1481853},
abstract = {Simple type systems perform compositional reasoning in that the type of a term depends only on the types of its subterms, and not on their semantics. Contracts offer more expressive abstractions, but static contract checking systems typically violate those abstractions and base their reasoning directly upon the semantics of terms. Pragmatically, this noncompositionality makes the decidability of static checking unpredictable.We first show how compositional reasoning may be restored using standard type-theoretic techniques, namely existential types and subtyping. Despite its compositional nature, our type system is exact, in that the type of a term can completely capture its semantics, hence demonstrating that precision and compositionality are compatible. We then address predictability of static checking for contract types by giving a type-checking algorithm for an important class of programs with contract predicates drawn from a decidable theory. Our algorithm relies crucially on the fact that the type of a term depends only the types of its subterms (which fall into the decidable theory) and not their semantics (which will not, in general).},
booktitle = {Proceedings of the 3rd Workshop on Programming Languages Meets Program Verification},
pages = {27-–38},
numpages = {12},
keywords = {abstraction, dependent types, refinement types, compositional reasoning},
location = {Savannah, GA, USA},
series = {PLPV '09}
}


@inproceedings{10.1007/978-3-540-85373-2_15,
  author    = {Herhut, Stephan
               and Scholz, Sven-Bodo
               and Bernecky, Robert
               and Grelck, Clemens
               and Trojahner, Kai},
  editor    = {Chitil, Olaf
               and Horv{\'a}th, Zolt{\'a}n
               and Zs{\'o}k, Vikt{\'o}ria},
  title     = {From Contracts Towards Dependent Types: Proofs by Partial Evaluation},
  booktitle = {Implementation and Application of Functional Languages},
  year      = {2008},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {254--273},
  abstract  = {The specification and resolution of non-trivial domain constraints has become a well-recognised measure for improving the stability of large software systems. In this paper we propose an approach based on partial evaluation which tries to prove such constraints statically as far as possible and inserts efficient dynamic checks otherwise.},
  isbn      = {978-3-540-85373-2}
}

@inproceedings{10.1145/581478.581484,
  author    = {Findler, Robert Bruce and Felleisen, Matthias},
  title     = {Contracts for Higher-Order Functions},
  year      = {2002},
  isbn      = {1581134878},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/581478.581484},
  doi       = {10.1145/581478.581484},
  abstract  = {Assertions play an important role in the construction of robust software. Their use in programming languages dates back to the 1970s. Eiffel, an object-oriented programming language, wholeheartedly adopted assertions and developed the "Design by Contract" philosophy. Indeed, the entire object-oriented community recognizes the value of assertion-based contracts on methods.In contrast, languages with higher-order functions do not support assertion-based contracts. Because predicates on functions are, in general, undecidable, specifying such predicates appears to be meaningless. Instead, the functional languages community developed type systems that statically approximate interesting predicates.In this paper, we show how to support higher-order function contracts in a theoretically well-founded and practically viable manner. Specifically, we introduce λcon, a typed lambda calculus with assertions for higher-order functions. The calculus models the assertion monitoring system that we employ in DrScheme. We establish basic properties of the model (type soundness, etc.) and illustrate the usefulness of contract checking with examples from DrScheme's code base.We believe that the development of an assertion system for higher-order functions serves two purposes. On one hand, the system has strong practical potential because existing type systems simply cannot express many assertions that programmers would like to state. On the other hand, an inspection of a large base of invariants may provide inspiration for the direction of practical future type system research.},
  booktitle = {Proceedings of the Seventh ACM SIGPLAN International Conference on Functional Programming},
  pages     = {48--59},
  numpages  = {12},
  keywords  = {behavioral specifications, contracts, higher-order functions, solfware reliability, predicate typing},
  location  = {Pittsburgh, PA, USA},
  series    = {ICFP '02}
}

@inproceedings{10.1145/1926385.1926409,
  author    = {Ahmed, Amal and Findler, Robert Bruce and Siek, Jeremy G. and Wadler, Philip},
  title     = {Blame for All},
  year      = {2011},
  isbn      = {9781450304900},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/1926385.1926409},
  doi       = {10.1145/1926385.1926409},
  abstract  = {Several programming languages are beginning to integrate static and dynamic typing, including Racket (formerly PLT Scheme), Perl 6, and C# 4.0 and the research languages Sage (Gronski, Knowles, Tomb, Freund, and Flanagan, 2006) and Thorn (Wrigstad, Eugster, Field, Nystrom, and Vitek, 2009). However, an important open question remains, which is how to add parametric polymorphism to languages that combine static and dynamic typing. We present a system that permits a value of dynamic type to be cast to a polymorphic type and vice versa, with relational parametricity enforced by a kind of dynamic sealing along the lines proposed by Matthews and Ahmed (2008) and Neis, Dreyer, and Rossberg (2009). Our system includes a notion of blame, which allows us to show that when casting between a more-precise type and a less-precise type, any cast failures are due to the less-precisely-typed portion of the program. We also show that a cast from a subtype to its supertype cannot fail.},
  booktitle = {Proceedings of the 38th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
  pages     = {201--214},
  numpages  = {14},
  keywords  = {casts, blame tracking, lambda-calculus, coercions},
  location  = {Austin, Texas, USA},
  series    = {POPL '11}
}

@inproceedings{10.1145/99370.99404,
  author    = {Wadler, Philip},
  title     = {Theorems for Free!},
  year      = {1989},
  isbn      = {0897913280},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/99370.99404},
  doi       = {10.1145/99370.99404},
  booktitle = {Proceedings of the Fourth International Conference on Functional Programming Languages and Computer Architecture},
  pages     = {347–359},
  numpages  = {13},
  location  = {Imperial College, London, United Kingdom},
  series    = {FPCA '89}
}

@article{10.1145/3110283,
  author     = {Ahmed, Amal and Jamner, Dustin and Siek, Jeremy G. and Wadler, Philip},
  title      = {Theorems for Free for Free: Parametricity, with and without Types},
  year       = {2017},
  issue_date = {September 2017},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {1},
  number     = {ICFP},
  url        = {https://doi.org/10.1145/3110283},
  doi        = {10.1145/3110283},
  abstract   = {The polymorphic blame calculus integrates static typing, including universal types, with dynamic typing. The primary challenge with this integration is preserving parametricity: even dynamically-typed code should satisfy it once it has been cast to a universal type. Ahmed et al. (2011) employ runtime type generation in the polymorphic blame calculus to preserve parametricity, but a proof that it does so has been elusive. Matthews and Ahmed (2008) gave a proof of parametricity for a closely related system that combines ML and Scheme, but later found a flaw in their proof. In this paper we present an improved version of the polymorphic blame calculus and we prove that it satisfies relational parametricity. The proof relies on a step-indexed Kripke logical relation. The step-indexing is required to make the logical relation well-defined in the case for the dynamic type. The possible worlds include the mapping of generated type names to their types and the mapping of type names to relations. We prove the Fundamental Property of this logical relation and that it is sound with respect to contextual equivalence. To demonstrate the utility of parametricity in the polymorphic blame calculus, we derive two free theorems. },
  journal    = {Proceedings of the ACM on Programming Languages},
  month      = aug,
  articleno  = {39},
  numpages   = {28},
  keywords   = {dynamic typing, logical relation, parametricity, gradual typing}
}


@inproceedings{10.1145/2103776.2103779,
  author    = {Osera, Peter-Michael and Sj\"{o}berg, Vilhelm and Zdancewic, Steve},
  title     = {Dependent Interoperability},
  year      = {2012},
  isbn      = {9781450311250},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/2103776.2103779},
  doi       = {10.1145/2103776.2103779},
  abstract  = {In this paper we study the problem of interoperability --- combining constructs from two separate programming languages within one program --- in the case where one of the two languages is dependently typed and the other is simply typed.We present a core calculus called SD, which combines dependently- and simply-typed sub-languages and supports user-defined (dependent) datatypes, among other standard features. SD has "boundary terms" that mediate the interaction between the two sub-languages. The operational semantics of SD demonstrates how the necessary dynamic checks, which must be done when passing a value from the simply-typed world to the dependently typed world, can be extracted from the dependent type constructors themselves, modulo user-defined functions for marshaling values across the boundary.We establish type-safety and other meta-theoretic properties of SD, and contrast this approach to others in the literature.},
  booktitle = {Proceedings of the Sixth Workshop on Programming Languages Meets Program Verification},
  pages     = {3--14},
  numpages  = {12},
  keywords  = {dependent types, contracts, language interoperability},
  location  = {Philadelphia, Pennsylvania, USA},
  series    = {PLPV '12}
}

@book{plfa20.07,
  author = {Philip Wadler and Wen Kokke and Jeremy G. Siek},
  title  = {Programming Language Foundations in {A}gda},
  year   = {2020},
  month  = jul,
  url    = {http://plfa.inf.ed.ac.uk/20.07/}
}

@techreport{Martin-Lof-1971,
  author      = {Martin-L{\"o}f, Per},
  title       = {A Theory of Types},
  institution = {University of Stockholm},
  year        = {1971}
}

@techreport{Martin-Lof-1972,
  author      = {Martin-L{\"o}f, Per},
  title       = {An intuitionistic theory of types},
  institution = {University of Stockholm},
  year        = {1972}
}


@inproceedings{10.1007/3-540-45842-5_4,
  author    = {Coquand, Thierry
               and Takeyama, Makoto},
  editor    = {Callaghan, Paul
               and Luo, Zhaohui
               and McKinna, James
               and Pollack, Robert
               and Pollack, Robert},
  title     = {An Implementation of Type:Type},
  booktitle = {Types for Proofs and Programs},
  year      = {2002},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {53--62},
  abstract  = {We present a denotational semantics of a type system with dependent types, where types are interpreted as finitary projections. We prove then the correctness of a type-checking algorithm w.r.t. this semantics. In this way, we can justify some simple optimisation in this algorithm. We then sketch how to extend this semantics to allow a simple record mechanism with manifest fields.},
  isbn      = {978-3-540-45842-5}
}

@techreport{cardelli1986polymorphic,
  title       = {A Polymorphic [lambda]-calculus with Type: Type},
  author      = {Cardelli, Luca},
  year        = {1986},
  month       = May,
  address     = {130 Lytton Avenue, Palo Alto, CA 94301},
  institution = {DEC System Research Center}
}


@article{10.1145/103135.103138,
  author     = {Abadi, Mart\'{\i}n and Cardelli, Luca and Pierce, Benjamin and Plotkin, Gordon},
  title      = {Dynamic Typing in a Statically Typed Language},
  year       = {1991},
  issue_date = {April 1991},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {13},
  number     = {2},
  issn       = {0164-0925},
  url        = {https://doi.org/10.1145/103135.103138},
  doi        = {10.1145/103135.103138},
  abstract   = {Statically typed programming languages allow earlier error checking, better enforcement of diciplined programming styles, and the generation of more efficient object code than languages where all type consistency checks are performed at run time. However, even in statically typed languages, there is often the need to deal with datawhose type cannot be determined at compile time. To handle such situations safely, we propose to add a type Dynamic whose values are pairs of a value v and a type tag T where v has the type denoted by T. Instances of Dynamic are built with an explicit tagging construct and inspected with a type safe typecase construct.This paper explores the syntax, operational semantics, and denotational semantics of a simple language that includes the type Dynamic. We give examples of how dynamically typed values can be used in programming. Then we discuss an operational semantics for our language and obtain a soundness theorem. We present two formulations of the denotational semantics of this language and relate them to the operational semantics. Finally, we consider the implications of polymorphism and some implementation issues.},
  journal    = {ACM Transactions on Programming Languages and Systems},
  pages      = {237--268},
  numpages   = {32},
  keywords   = {theory}
}

@misc{cardelli1988phase,
  title     = {Phase distinctions in type theory},
  author    = {Cardelli, Luca},
  year      = {1988},
  publisher = {Citeseer}
}

@article{TAKAHASHI1995120,
  title    = {Parallel Reductions in $\lambda$-Calculus},
  journal  = {Information and Computation},
  volume   = {118},
  number   = {1},
  pages    = {120-127},
  year     = {1995},
  issn     = {0890-5401},
  doi      = {https://doi.org/10.1006/inco.1995.1057},
  url      = {https://www.sciencedirect.com/science/article/pii/S0890540185710577},
  author   = {M. Takahashi},
  abstract = {The notion of parallel reduction is extracted from the simple proof of the Church-Rosser theorem by Tait and Martin-Löf. Intuitively, this means to reduce a number of redexes (existing in a λ-term) simultaneously. Thus in the case of β-reduction the effect of a parallel reduction is same as that of a "complete development" which is defined by using "residuals" of β-redexes. A nice feature of parallel reduction, however, is that it can be defined directly by induction on the structure of λ-terms (without referring to residuals or other auxiliary notions), and the inductive definition provides us exactly what we need in proving the theorem inductively. Moreover, the notion can be easily extended to other reduction systems such as Girard′s second-order system F and Gödel′s system T. In this paper, after reevaluating the significance of the notion of parallel reduction in Tait-and-Martin-Löf type proofs of the Church-Rosser theorems, we show that the notion of parallel reduction is also useful in giving short and direct proofs of some other fundamental theorems in reduction theory of λ-calculus; among others, we give such simple proofs of the standardization theorem for β-reduction (a special case of which is known as the leftmost reduction theorem for β-reduction), the quasi-leftmost reduction theorem for β-reduction, the postponement theorem of η-reduction (in βη-reduction), and the leftmost reduction theorem for βη-reduction.}
}

@article{COQUAND1996167,
  title    = {An algorithm for type-checking dependent types},
  journal  = {Science of Computer Programming},
  volume   = {26},
  number   = {1},
  pages    = {167-177},
  year     = {1996},
  issn     = {0167-6423},
  doi      = {https://doi.org/10.1016/0167-6423(95)00021-6},
  url      = {https://www.sciencedirect.com/science/article/pii/0167642395000216},
  author   = {Thierry Coquand},
  abstract = {We present a simple type-checker for a language with dependent types and let expressions, with a simple proof of correctness.}
}


@inproceedings{10.1145/1836089.1836113,
  author    = {Snow, Zachary and Baelde, David and Nadathur, Gopalan},
  title     = {A Meta--Programming Approach to Realizing Dependently Typed Logic Programming},
  year      = {2010},
  isbn      = {9781450301329},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/1836089.1836113},
  doi       = {10.1145/1836089.1836113},
  abstract  = {Dependently typed λ-calculi such as the Logical Framework (LF) can encode relationships between terms in types and can naturally capture correspondences between formulas and their proofs. Such calculi can also be given a logic programming interpretation: the Twelf system is based on such an interpretation of LF. We consider here whether a conventional logic programming language can provide the benefits of a Twelf-like system for encoding type and proof-and-formula dependencies. In particular, we present a simple mapping from LF specifications to a set of formulas in the higher-order hereditary Harrop (hohh) language, that relates derivations and proof-search between the two frameworks. We then show that this encoding can be improved by exploiting knowledge of the well-formedness of the original LF specifications to elide much redundant type-checking information. The resulting logic program has a structure that closely resembles the original specification, thereby allowing LF specifications to be viewed as hohh meta-programs. Using the Teyjus implementation of λ Prolog, we show that our translation provides an efficient means for executing LF specifications, complementing the ability that the Twelf system provides for reasoning about them.},
  booktitle = {Proceedings of the 12th International ACM SIGPLAN Symposium on Principles and Practice of Declarative Programming},
  pages     = {187--198},
  numpages  = {12},
  keywords  = {logical frameworks, dependently typed lambda calculi, higher-order logic programming, translation},
  location  = {Hagenberg, Austria},
  series    = {PPDP '10}
}
}

@article{D_az_Caro_2013,
  title     = {Non determinism through type isomorphism},
  volume    = {113},
  issn      = {2075-2180},
  url       = {http://dx.doi.org/10.4204/EPTCS.113.13},
  doi       = {10.4204/eptcs.113.13},
  journal   = {Electronic Proceedings in Theoretical Computer Science},
  publisher = {Open Publishing Association},
  author    = {Díaz-Caro, Alejandro and Dowek, Gilles},
  year      = {2013},
  month     = {Mar},
  pages     = {137--144}
}


@article{DOWEK20111231,
  title    = {On the expressive power of schemes},
  journal  = {Information and Computation},
  volume   = {209},
  number   = {9},
  pages    = {1231-1245},
  year     = {2011},
  issn     = {0890-5401},
  doi      = {https://doi.org/10.1016/j.ic.2011.06.003},
  url      = {https://www.sciencedirect.com/science/article/pii/S0890540111001052},
  author   = {Gilles Dowek and Ying Jiang},
  keywords = {Natural deduction, Proof normalization, Bound variable},
  abstract = {We present a calculus, called the scheme-calculus, that permits to express natural deduction proofs in various theories. Unlike λ-calculus, the syntax of this calculus sticks closely to the syntax of proofs, in particular, no names are introduced for the hypotheses. We show that despite its non-determinism, some typed scheme-calculi have the same expressivity as the corresponding typed λ-calculi.}
}

@inproceedings{SchaeferEtAl:2015:Autosubst:-Reasoning,
  author    = {Sch{\"a}fer, Steven
               and Tebbi, Tobias
               and Smolka, Gert},
  editor    = {Urban, Christian
               and Zhang, Xingyuan},
  title     = {Autosubst: Reasoning with de Bruijn Terms and Parallel Substitutions},
  booktitle = {Interactive Theorem Proving},
  year      = {2015},
  publisher = {Springer International Publishing},
  address   = {Cham},
  pages     = {359--374},
  abstract  = {Reasoning about syntax with binders plays an essential role in the formalization of the metatheory of programming languages. While the intricacies of binders can be ignored in paper proofs, formalizations involving binders tend to be heavyweight. We present a discipline for syntax with binders based on de Bruijn terms and parallel substitutions, with a decision procedure covering all assumption-free equational substitution lemmas. The approach is implemented in the Coq library Autosubst, which additionally derives substitution operations and proofs of substitution lemmas for custom term types. We demonstrate the effectiveness of the approach with several case studies, including part A of the POPLmark challenge.},
  isbn      = {978-3-319-22102-1}
}


@inproceedings{10.1145/292540.292560,
  author    = {Xi, Hongwei and Pfenning, Frank},
  title     = {Dependent Types in Practical Programming},
  year      = {1999},
  isbn      = {1581130953},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/292540.292560},
  abstract  = {We present an approach to enriching the type system of ML with a restricted form of dependent types, where type index objects are drawn from a constraint domain C, leading to the DML(C) language schema. This allows specification and inference of significantly more precise type information, facilitating program error detection and compiler optimization. A major complication resulting from introducing dependent types is that pure type inference for the enriched system is no longer possible, but we show that type-checking a sufficiently annotated program in DML(C) can be reduced to constraint satisfaction in the constraint domain C. We exhibit the unobtrusiveness of our approach through practical examples and prove that DML(C) is conservative over ML. The main contribution of the paper lies in our language design, including the formulation of type-checking rules which makes the approach practical. To our knowledge, no previous type system for a general purpose programming language such as ML has combined dependent types with features including datatype declarations, higher-order functions, general recursions, let-polymorphism, mutable references, and exceptions. In addition, we have finished a prototype implementation of DML(C) for an integer constraint domain C, where constraints are linear inequalities (Xi and Pfenning 1998).},
  booktitle = {Proceedings of the 26th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
  pages     = {214--227},
  numpages  = {14},
  location  = {San Antonio, Texas, USA},
  series    = {POPL '99}
}



@phdthesis{Hongweithseis,
  author   = {Xi,Hongwei},
  year     = {1998},
  title    = {Dependent types in practical programming},
  journal  = {ProQuest Dissertations and Theses},
  pages    = {188},
  note     = {Copyright - Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works; Last updated - 2021-04-02},
  abstract = {Programming is a notoriously error-prone process, and a great deal of evidence in practice has demonstrated that the use of a type system in a programming language can effectively detect program errors at compile-time. Moreover, some recent studies have indicated that the use of types can lead to significant enhancement of program performance at run-time. For the sake of practicality of type-checking, most type systems developed for general purpose programming languages tend to be simple and coarse, and this leaves ample room for improvement. As an advocate of types, this thesis addresses the issue of designing a type system for practical programming in which a notion of dependent types is available, leading to more accurate capture of program invariants with types. In contrast to developing a type theory with dependent types and then designing upon it a functional programming language, we study practical methods for extending the type systems of existing programming languages with dependent types. We present an approach to enriching the type system of ML with a special form of dependent types, where type index objects are restricted to some constraint domains C, leading to the DML(C) language schema. The aim is to provide for specification and inference of significantly more precise type information compared with the current type system of ML, facilitating program error detection and compiler optimization. A major complication resulting from introducing dependent types is that pure type inference for the resulting system is no longer possible, but we show that type-checking a sufficiently annotated program in DML(C) can be reduced to constraint satisfaction in the constraint domain C. Therefore, type-checking in DML(C) can be made practical for those constraint domains C for which efficient constraint solvers can be provided. We prove that DML(C) is a conservative extension over ML, that is, a valid ML program is always valid in DML(C). Also we exhibit the unobtrusiveness of our approach through many practical examples. As a significant application, we also demonstrate the elimination of array bound checks in real code with the use of dependent types. All the examples have been verified in a prototype implementation of a type-checker for DML( C), where C is some constraint domain in which constraints are linear inequalities on integers. This is another attempt towards refining the type systems of existing programing languages, following the step of refinement types (Freeman and Henning 1991).},
  keywords = {Applied sciences; Pure sciences; Array bounds checking; Compiler optimization; Dependent types; Practical programming; Computer science; Mathematics; 0405:Mathematics; 0984:Computer science},
  isbn     = {978-0-599-17233-3},
  language = {English}
}


@article{DependentMLAnapproachtopracticalprogrammingwithdependenttypes,
  author   = {Xi,Hongwei},
  year     = {2007},
  month    = {03},
  title    = {Dependent ML An approach to practical programming with dependent types},
  journal  = {Journal of Functional Programming},
  volume   = {17},
  number   = {2},
  pages    = {215-286},
  note     = {Copyright - 2006 Cambridge University Press; Last updated - 2010-06-08},
  abstract = {We present an approach to enriching the type system of ML with a restricted form of dependent types, where type index terms are required to be drawn from a given type index language ${\cal L}$ that is completely separate from run-time programs, leading to the DML(${\cal L}$) language schema. This enrichment allows for specification and inference of significantly more precise type information, facilitating program error detection and compiler optimization. The primary contribution of the paper lies in our language design, which can effectively support the use of dependent types in practical programming. In particular, this design makes it both natural and straightforward to accommodate dependent types in the presence of effects such as references and exceptions. PUBLICATION ABSTRACT]},
  keywords = {Computers},
  isbn     = {09567968},
  language = {English}
}


@inproceedings{10.1145/1863543.1863592,
  author    = {Bernardy, Jean-Philippe and Jansson, Patrik and Paterson, Ross},
  title     = {Parametricity and Dependent Types},
  year      = {2010},
  isbn      = {9781605587943},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/1863543.1863592},
  doi       = {10.1145/1863543.1863592},
  abstract  = {Reynolds' abstraction theorem shows how a typing judgement in System F can be translated into a relational statement (in second order predicate logic) about inhabitants of the type. We (in second order predicate logic) about inhabitants of the type. We obtain a similar result for a single lambda calculus (a pure type system), in which terms, types and their relations are expressed. Working within a single system dispenses with the need for an interpretation layer, allowing for an unusually simple presentation. While the unification puts some constraints on the type system (which we spell out), the result applies to many interesting cases, including dependently-typed ones.},
  booktitle = {Proceedings of the 15th ACM SIGPLAN International Conference on Functional Programming},
  pages     = {345–356},
  numpages  = {12},
  keywords  = {abstraction theorem, free theorems, pure type system},
  location  = {Baltimore, Maryland, USA},
  series    = {ICFP '10}
}


@article{10.1145/1932681.1863592,
  author     = {Bernardy, Jean-Philippe and Jansson, Patrik and Paterson, Ross},
  title      = {Parametricity and Dependent Types},
  year       = {2010},
  issue_date = {September 2010},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {45},
  number     = {9},
  issn       = {0362-1340},
  url        = {https://doi.org/10.1145/1932681.1863592},
  doi        = {10.1145/1932681.1863592},
  abstract   = {Reynolds' abstraction theorem shows how a typing judgement in System F can be translated into a relational statement (in second order predicate logic) about inhabitants of the type. We (in second order predicate logic) about inhabitants of the type. We obtain a similar result for a single lambda calculus (a pure type system), in which terms, types and their relations are expressed. Working within a single system dispenses with the need for an interpretation layer, allowing for an unusually simple presentation. While the unification puts some constraints on the type system (which we spell out), the result applies to many interesting cases, including dependently-typed ones.},
  journal    = {ACM SIGPLAN Notices},
  month      = sep,
  pages      = {345--356},
  numpages   = {12},
  keywords   = {abstraction theorem, free theorems, pure type system}
}

@article{extendedabstract,
  author  = {Lemay, Mark and Zhang, Cheng and Blair, William},
  title   = {Developing a Dependently Typed Language with Runtime Proof Search (Extended Abstract)},
  year    = {2020},
  journal = {Workshop on Type-Driven Development}
}

@article{10.1145/3450952,
  author     = {Dunfield, Jana and Krishnaswami, Neel},
  title      = {Bidirectional Typing},
  year       = {2021},
  issue_date = {May 2021},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {54},
  number     = {5},
  issn       = {0360-0300},
  url        = {https://doi.org/10.1145/3450952},
  doi        = {10.1145/3450952},
  abstract   = {Bidirectional typing combines two modes of typing: type checking, which checks that a program satisfies a known type, and type synthesis, which determines a type from the program. Using checking enables bidirectional typing to support features for which inference is undecidable; using synthesis enables bidirectional typing to avoid the large annotation burden of explicitly typed languages. In addition, bidirectional typing improves error locality. We highlight the design principles that underlie bidirectional type systems, survey the development of bidirectional typing from the prehistoric period before Pierce and Turner’s local type inference to the present day, and provide guidance for future investigations.},
  journal    = {ACM Computing Surveys},
  month      = may,
  articleno  = {98},
  numpages   = {38},
  keywords   = {type inference, Type checking}
}

@inproceedings{10.1007/3-540-13346-1_1,
  author    = {Burstall, R.
               and Lampson, B.},
  editor    = {Kahn, Gilles
               and MacQueen, David B.
               and Plotkin, Gordon},
  title     = {A kernel language for abstract data types and modules},
  booktitle = {Semantics of Data Types},
  year      = {1984},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {1--50},
  abstract  = {A small set of constructs can simulate a wide variety of apparently distinct features in modern programming languages. Using typed lambda calculus with bindings, declarations, and types as first-class values, we show how to build modules, interfaces and implementations, abstract data types, generic types, recursive types, and unions. The language has a concise operational semantics given by inference rules.},
  isbn      = {978-3-540-38891-3}
}


@inbook{10.1145/512644.512671,
  author    = {Meyer, Albert R. and Reinhold, Mark B.},
  title     = {"Type" is Not a Type},
  year      = {1986},
  isbn      = {9781450373470},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/512644.512671},
  abstract  = {A function has a dependent type when the type of its result depends upon the value of its argument. Dependent types originated in the type theory of intuitionistic mathematics and have reappeared independently in programming languages such as CLU, Pebble, and Russell. Some of these languages make the assumption that there exists a type-of-all-types which is its own type as well as the type of all other types. Girard proved that this approach is inconsistent from the perspective of intuitionistic logic. We apply Girard's techniques to establish that the type-of-all-types assumption creates serious pathologies from a programming perspective: a system using this assumption is inherently not normalizing, term equality is undecidable, and the resulting theory fails to be a conservative extension of the theory of the underlying base types. The failure of conservative extension means that classical reasoning about programs in such a system is not sound.},
  booktitle = {Proceedings of the 13th ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages},
  pages     = {287--295},
  numpages  = {9}
}


@techreport{Reinhold89typecheckingis,
  author      = {Mark B. Reinhold},
  title       = {Typechecking is Undecidable When `Type' is a Type},
  institution = {},
  year        = {1989}
}

@article{mcbride_mckinna_2004,
  title     = {The view from the left},
  volume    = {14},
  doi       = {10.1017/S0956796803004829},
  number    = {1},
  journal   = {Journal of Functional Programming},
  publisher = {Cambridge University Press},
  author    = {Mcbride, Conor and Mckinna, James},
  year      = {2004},
  pages     = {69--111}
}


@inproceedings{coquand1992pattern,
  title     = {Pattern matching with dependent types},
  author    = {Coquand, Thierry},
  booktitle = {Proceedings of the Workshop on Types for Proofs and Programs},
  pages     = {71--83},
  year      = {1992}
}

@article{cockx_devriese_2018,
  title     = {Proof-relevant unification: Dependent pattern matching with only the axioms of your type theory},
  volume    = {28},
  doi       = {10.1017/S095679681800014X},
  journal   = {Journal of Functional Programming},
  publisher = {Cambridge University Press},
  author    = {Cockx, Jesper and Devriese, Dominique},
  year      = {2018},
  pages     = {e12}
}


@inproceedings{10.1145/1481848.1481856,
  author    = {Stump, Aaron and Deters, Morgan and Petcher, Adam and Schiller, Todd and Simpson, Timothy},
  title     = {Verified Programming in Guru},
  year      = {2009},
  isbn      = {9781605583303},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi-org.ezproxy.bu.edu/10.1145/1481848.1481856},
  doi       = {10.1145/1481848.1481856},
  abstract  = {Operational Type Theory (OpTT) is a type theory allowing possibly diverging programs
               while retaining decidability of type checking and a consistent logic. This is done
               by distinguishing proofs and (program) terms, as well as formulas and types. The theory
               features propositional equality on type-free terms, which facilitates reasoning about
               dependently typed programs. OpTT has been implemented in the Guru verified programming
               language, which includes a type- and proof-checker, and a compiler to efficient C
               code. In addition to the core OpTT, Guru implements a number of extensions, including
               ones for verification of programs using mutable state and input/output. This paper
               gives an introduction to verified programming in Guru.},
  booktitle = {Proceedings of the 3rd Workshop on Programming Languages Meets Program Verification},
  pages     = {49--58},
  numpages  = {10},
  keywords  = {language-based verification, operational type theory, dependently typed programming},
  location  = {Savannah, GA, USA},
  series    = {PLPV '09}
}

@inproceedings{10.1007/3-540-45842-5_13,
  author    = {McBride, Conor},
  editor    = {Callaghan, Paul
               and Luo, Zhaohui
               and McKinna, James
               and Pollack, Robert
               and Pollack, Robert},
  title     = {Elimination with a Motive},
  booktitle = {Types for Proofs and Programs},
  year      = {2002},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {197--216},
  abstract  = {Elimination rules tell us how we may exploit hypotheses in the course of a proof. Many common elimination rules, such as ∨-elim and the induction principles for inductively defined datatypes and relations, are parametric in their conclusion. We typically instantiate this parameter with the goal we are trying to prove, and acquire subproblems specialising this goal to particular circumstances in which the eliminated hypothesis holds. This paper describes a generic tactic, Elim, which supports this ubiquitous idiom in interactive proof and subsumes the functionality of the more specific `induction' and `inversion' tactics found in systems like Coq and Lego[6][7][15]. Elim also supports user-derived rules which follow the same style.},
  isbn      = {978-3-540-45842-5}
}

@article{mcbride2000dependently,
  title     = {Dependently typed functional programs and their proofs},
  author    = {McBride, Conor},
  year      = {2000},
  publisher = {University of Edinburgh. College of Science and Engineering. School of~…}
}

@article{gradualcorrectnessea,
  author = {Lemay, Mark and Fu, Qiancheng amd Fu, Qiancheng},
  title  = {Gradual Correctness: a Dynamically Bidirectional Full-Spectrum Dependent Type Theory (Extended Abstract)},
  year   = {2021},
  series = {TyDe 2021}
}

@article{MILNER1978348,
  title    = {A theory of type polymorphism in programming},
  journal  = {Journal of Computer and System Sciences},
  volume   = {17},
  number   = {3},
  pages    = {348-375},
  year     = {1978},
  issn     = {0022-0000},
  doi      = {https://doi.org/10.1016/0022-0000(78)90014-4},
  url      = {https://www.sciencedirect.com/science/article/pii/0022000078900144},
  author   = {Robin Milner},
  abstract = {The aim of this work is largely a practical one. A widely employed style of programming, particularly in structure-processing languages which impose no discipline of types, entails defining procedures which work well on objects of a wide variety. We present a formal type discipline for such polymorphic procedures in the context of a simple programming language, and a compile time type-checking algorithm W which enforces the discipline. A Semantic Soundness Theorem (based on a formal semantics for the language) states that well-type programs cannot “go wrong” and a Syntactic Soundness Theorem states that if W accepts a program then it is well typed. We also discuss extending these results to richer languages; a type-checking algorithm based on W is in fact already implemented and working, for the metalanguage ML in the Edinburgh LCF system.}
}


@article{10.2307/2274575,
  issn      = {00224812},
  url       = {http://www.jstor.org/stable/2274575},
  author    = {Jan M. Smith},
  journal   = {The Journal of Symbolic Logic},
  number    = {3},
  pages     = {840--845},
  publisher = {Association for Symbolic Logic},
  title     = {The Independence of Peano's Fourth Axiom from Martin-Löf's Type Theory Without Universes},
  volume    = {53},
  year      = {1988}
}

@article{WRIGHT199438,
  title    = {A Syntactic Approach to Type Soundness},
  journal  = {Information and Computation},
  volume   = {115},
  number   = {1},
  pages    = {38-94},
  year     = {1994},
  issn     = {0890-5401},
  doi      = {https://doi.org/10.1006/inco.1994.1093},
  url      = {https://www.sciencedirect.com/science/article/pii/S0890540184710935},
  author   = {A.K. Wright and M. Felleisen},
  abstract = {We present a new approach to proving type soundness for Hindley/Milner-style polymorphic type systems. The keys to our approach are (1) an adaptation of subject reduction theorems from combinatory logic to programming languages, and (2) the use of rewriting techniques for the specification of the language semantics. The approach easily extends from polymorphic functional languages to imperative languages that provide references, exceptions, continuations, and similar features. We illustrate the technique with a type soundness theorem for the core of Standard ML, which includes the first type soundness proof for polymorphic exceptions and continuations.}
}

@article{10.1016/0890-5401(88)90005-3,
  author     = {Coquand, Thierry and Huet, Gerard},
  title      = {The Calculus of Constructions},
  year       = {1988},
  issue_date = {February/March 1988},
  publisher  = {Academic Press, Inc.},
  address    = {USA},
  volume     = {76},
  number     = {2--3},
  issn       = {0890--5401},
  url        = {https://doi.org/10.1016/0890-5401(88)90005-3},
  doi        = {10.1016/0890-5401(88)90005-3},
  journal    = {Information and Computation},
  month      = feb,
  pages      = {95--120},
  numpages   = {26}
}

@article{COQUAND198895,
  title   = {The calculus of constructions},
  journal = {Information and Computation},
  volume  = {76},
  number  = {2},
  pages   = {95-120},
  year    = {1988},
  issn    = {0890-5401},
  doi     = {https://doi.org/10.1016/0890-5401(88)90005-3},
  url     = {https://www.sciencedirect.com/science/article/pii/0890540188900053},
  author  = {Thierry Coquand and Gérard Huet}
}


@techreport{christiansen2013bidirectional,
  title  = {Bidirectional typing rules: A tutorial},
  author = {Christiansen, David Raymond},
  year   = {2013},
  url    = {https://davidchristiansen.dk/tutorials/bidirectional.pdf}
}


@phdthesis{luo1990extended,
  title  = {An Extended Calculus of Constructions},
  author = {Luo, Zhaohui},
  year   = {1990},
  school = {University of Edinburgh}
}


@book{luo1994computation,
  title  = {Computation and Reasoning: A Type Theory for Computer Science},
  author = {Luo, Zhaohui},
  year   = {1994}
}


@book{sorensen2006lectures,
  title     = {Lectures on the Curry-Howard Isomorphism},
  author    = {S{\o}rensen, Morten Heine and Urzyczyn, Pawel},
  year      = {2006},
  publisher = {Elsevier}
}

@inproceedings{10.1007/978-3-540-78499-9_26,
  author    = {Barras, Bruno
               and Bernardo, Bruno},
  editor    = {Amadio, Roberto},
  title     = {The Implicit Calculus of Constructions as a Programming Language with Dependent Types},
  booktitle = {Foundations of Software Science and Computational Structures},
  year      = {2008},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {365--379},
  abstract  = {In this paper, we show how Miquel's Implicit Calculus of Constructions (ICC) can be used as a programming language featuring dependent types. Since this system has an undecidable type-checking, we introduce a more verbose variant, called ICC* which fixes this issue. Datatypes and program specifications are enriched with logical assertions (such as preconditions, postconditions, invariants) and programs are decorated with proofs of those assertions. The point of using ICC* rather than the Calculus of Constructions (the core formalism of the Coq proof assistant) is that all of the static information (types and proof objects) is transparent, in the sense that it does not affect the computational behavior. This is concretized by a built-in extraction procedure that removes this static information. We also illustrate the main features of ICC* on classical examples of dependently typed programs.},
  isbn      = {978-3-540-78499-9}
}


@inproceedings{10.1007/3-540-45413-6_27,
  author    = {Miquel, Alexandre},
  editor    = {Abramsky, Samson},
  title     = {The Implicit Calculus of Constructions Extending Pure Type Systems with an Intersection Type Binder and Subtyping},
  booktitle = {Typed Lambda Calculi and Applications},
  year      = {2001},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {344--359},
  abstract  = {In this paper, we introduce a new type system, the Implicit Calculus of Constructions, which is a Curry-style variant of the Calculus of Constructions that we extend by adding an intersection type binder---called the implicit dependent product. Unlike the usual approach of Type Assignment Systems, the implicit product can be used at every place in the universe hierarchy. We study syntactical properties of this calculus such as the $\beta$$\eta$-subject reduction property, and we show that the implicit product induces a rich subtyping relation over the type system in a natural way. We also illustrate the specificities of this calculus by revisiting the impredicative encodings of the Calculus of Constructions, and we show that their translation into the implicit calculus helps to reflect the computational meaning of the underlying terms in a more accurate way.},
  isbn      = {978-3-540-45413-7}
}

@book{barendregt1992lambda,
  title     = {Lambda calculi with types},
  author    = {Barendregt, Henk P},
  year      = {1991},
  publisher = {Oxford: Clarendon Press}
}


@book{pierce2002types,
  title     = {Types and programming languages},
  author    = {Pierce, Benjamin C},
  year      = {2002},
  publisher = {MIT press}
}

@book{hofmann1997extensional,
  title     = {Extensional constructs in intensional type theory},
  author    = {Hofmann, Martin},
  year      = {1997},
  publisher = {Springer Science \& Business Media}
}

@incollection{aspinall2004dependent,
  title     = {Dependent types},
  author    = {Aspinall, David and Hofmann, Martin},
  booktitle = {Advanced Topics in Types and Programming Languages},
  pages     = {45--86},
  year      = {2004},
  publisher = {MIT Press}
}

@inproceedings{lennonbertrand:LIPIcs.ITP.2021.24,
  author    = {Lennon-Bertrand, Meven},
  title     = {{Complete Bidirectional Typing for the Calculus of Inductive Constructions}},
  booktitle = {12th International Conference on Interactive Theorem Proving (ITP 2021)},
  pages     = {24:1--24:19},
  series    = {Leibniz International Proceedings in Informatics (LIPIcs)},
  isbn      = {978-3-95977-188-7},
  issn      = {1868-8969},
  year      = {2021},
  volume    = {193},
  editor    = {Cohen, Liron and Kaliszyk, Cezary},
  publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik},
  address   = {Dagstuhl, Germany},
  url       = {https://drops.dagstuhl.de/opus/volltexte/2021/13919},
  urn       = {urn:nbn:de:0030-drops-139194},
  doi       = {10.4230/LIPIcs.ITP.2021.24},
  annote    = {Keywords: Bidirectional Typing, Calculus of Inductive Constructions, Coq, Proof Assistants}
}



@inproceedings{10.1007/978-3-642-28869-2_11,
  author    = {Dimoulas, Christos
               and Tobin-Hochstadt, Sam
               and Felleisen, Matthias},
  editor    = {Seidl, Helmut},
  title     = {Complete Monitors for Behavioral Contracts},
  booktitle = {Programming Languages and Systems},
  year      = {2012},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {214--233},
  abstract  = {A behavioral contract in a higher-order language may invoke methods of unknown objects. Although this expressive power allows programmers to formulate sophisticated contracts, it also poses a problem for language designers. Indeed, two distinct semantics have emerged for such method calls, dubbed lax and picky. While lax fails to protect components in certain scenarios, picky may blame an uninvolved party for a contract violation.},
  isbn      = {978-3-642-28869-2}
}

@article{10.1145/1925844.1926410,
  author     = {Dimoulas, Christos and Findler, Robert Bruce and Flanagan, Cormac and Felleisen, Matthias},
  title      = {Correct Blame for Contracts: No More Scapegoating},
  year       = {2011},
  issue_date = {January 2011},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {46},
  number     = {1},
  issn       = {0362-1340},
  url        = {https://doi.org/10.1145/1925844.1926410},
  doi        = {10.1145/1925844.1926410},
  abstract   = {Behavioral software contracts supplement interface information with logical assertions.
                A rigorous enforcement of contracts provides useful feedback to developers if it signals
                contract violations as soon as they occur and if it assigns blame to violators with
                preciseexplanations. Correct blame assignment gets programmers started with the debugging
                process and can significantly decrease the time needed to discover and fix bugs.Sadly
                the literature on contracts lacks a framework for making statements about the correctness
                of blame assignment and for validating such statements. This paper fills the gap and
                uses the framework to demonstrate how one of the proposed semantics for higher-order
                contracts satisfies this criteria and another semantics occasionally assigns blame
                to the wrong module.Concretely, the paper applies the framework to the lax enforcement
                of dependent higher-order contracts and the picky one. A higher-order dependent contract
                specifies constraints for the domain and range of higher-order functions and also
                relates arguments and results in auxiliary assertions. The picky semantics ensures
                that the use of arguments in the auxiliary assertion satisfies the domain contracts
                and the lax one does not. While the picky semantics discovers more contract violations
                than the lax one, it occasionally blames the wrong module. Hence the paper also introduces
                a third semantics, dubbed indy, which fixes the problems of the picky semantics without
                giving up its advantages.},
  journal    = {ACM SIGPLAN Notices},
  month      = jan,
  pages      = {215--226},
  numpages   = {12},
  keywords   = {behavioral contracts, higher-order programming, blame assignment}
}


@article{10.1145/3093333.3009856,
  author     = {Lehmann, Nico and Tanter, \'{E}ric},
  title      = {Gradual Refinement Types},
  year       = {2017},
  issue_date = {January 2017},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {52},
  number     = {1},
  issn       = {0362-1340},
  url        = {https://doi.org/10.1145/3093333.3009856},
  doi        = {10.1145/3093333.3009856},
  abstract   = { Refinement types are an effective language-based verification technique. However,
                as any expressive typing discipline, its strength is its weakness, imposing sometimes
                undesired rigidity. Guided by abstract interpretation, we extend the gradual typing
                agenda and develop the notion of gradual refinement types, allowing smooth evolution
                and interoperability between simple types and logically-refined types. In doing so,
                we address two challenges unexplored in the gradual typing literature: dealing with
                imprecise logical information, and with dependent function types. The first challenge
                leads to a crucial notion of locality for refinement formulas, and the second yields
                novel operators related to type- and term-level substitution, identifying new opportunity
                for runtime errors in gradual dependently-typed languages. The gradual language we
                present is type safe, type sound, and satisfies the refined criteria for gradually-typed
                languages of Siek et al. We also explain how to extend our approach to richer refinement
                logics, anticipating key challenges to consider. },
  journal    = {ACM SIGPLAN Notices},
  month      = jan,
  pages      = {775--788},
  numpages   = {14},
  keywords   = {abstract interpretation, refinement types, gradual typing}
}

@book{pitts1997semantics,
  title     = {Semantics and logics of computation},
  author    = {Pitts, Andrew M and Dybjer, Peter},
  volume    = {14},
  year      = {1997},
  publisher = {Cambridge University Press}
}

@inproceedings{10.1007/978-3-642-54833-8_6,
  author    = {Cockx, Jesper
               and Piessens, Frank
               and Devriese, Dominique},
  editor    = {Shao, Zhong},
  title     = {Overlapping and Order-Independent Patterns},
  booktitle = {Programming Languages and Systems},
  year      = {2014},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {87--106},
  abstract  = {Dependent pattern matching is a safe and efficient way to write programs and proofs in dependently typed languages. Current languages with dependent pattern matching treat overlapping patterns on a first-match basis, hence the order of the patterns can matter. Perhaps surprisingly, this order-dependence can even occur when the patterns do not overlap. To fix this confusing behavior, we developed a new semantics of pattern matching which treats all clauses as definitional equalities, even when the patterns overlap. A confluence check guarantees correctness in the presence of overlapping patterns. Our new semantics has two advantages. Firstly, it removes the order-dependence and thus makes the meaning of definitions clearer. Secondly, it allows the extension of existing definitions with new (consistent) evaluation rules. Unfortunately it also makes pattern matching harder to understand theoretically, but we give a theorem that helps to bridge this gap. An experimental implementation in Agda shows that our approach is feasible in practice too.},
  isbn      = {978-3-642-54833-8}
}

@inproceedings{10.1145/41625.41653,
  author    = {Wadler, P.},
  title     = {Views: A Way for Pattern Matching to Cohabit with Data Abstraction},
  year      = {1987},
  isbn      = {0897912152},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/41625.41653},
  doi       = {10.1145/41625.41653},
  abstract  = {Pattern matching and data abstraction are important concepts in designing programs, but they do not fit well together. Pattern matching depends on making public a free data type representation, while data abstraction depends on hiding the representation. This paper proposes the views mechanism as a means of reconciling this conflict. A view allows any type to be viewed as a free data type, thus combining the clarity of pattern matching with the efficiency of data abstraction.},
  booktitle = {Proceedings of the 14th ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages},
  pages     = {307--313},
  numpages  = {7},
  location  = {Munich, West Germany},
  series    = {POPL '87}
}


@inproceedings{10.1007/BFb0037116,
  author    = {Paulin-Mohring, Christine},
  editor    = {Bezem, Marc
               and Groote, Jan Friso},
  title     = {Inductive definitions in the system Coq rules and properties},
  booktitle = {Typed Lambda Calculi and Applications},
  year      = {1993},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {328--345},
  abstract  = {In the pure Calculus of Constructions, it is possible to represent data structures and predicates using higher-order quantification. However, this representation is not satisfactory, from the point of view of both the efficiency of the underlying programs and the power of the logical system. For these reasons, the calculus was extended with a primitive notion of inductive definitions [8]. This paper describes the rules for inductive definitions in the system Coq. They are general enough to be seen as one formulation of adding inductive definitions to a typed lambda-calculus. We prove strong normalization for a subsystem of Coq corresponding to the pure Calculus of Constructions plus Inductive Definitions with only weak eliminations.},
  isbn      = {978-3-540-47586-6}
}
@inproceedings{Moh93,
  author      = {C. Paulin-Mohring},
  booktitle   = {Proceedings of the conference Typed Lambda Calculi and Applications},
  editor      = {M. Bezem and J.-F. Groote},
  institution = {LIP-ENS Lyon},
  note        = {LIP research report 92-49},
  number      = 664,
  series      = {Lecture Notes in Computer Science},
  title       = {{Inductive Definitions in the System {Coq} - 
                 Rules and Properties}},
  type        = {research report},
  year        = 1993
}


@article{10.1145/3158150,
  author     = {Chandra, Kartik and Bodik, Rastislav},
  title      = {Bonsai: Synthesis-Based Reasoning for Type Systems},
  year       = {2017},
  issue_date = {January 2018},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {2},
  number     = {POPL},
  url        = {https://doi.org/10.1145/3158150},
  doi        = {10.1145/3158150},
  abstract   = {When designing a type system, we may want to mechanically check the design to guide its further development. We describe algorithms that perform symbolic reasoning about executable models of type systems. The algorithms support three queries. First, they check type soundness and synthesize a counterexample program if such a soundness bug is found. Second, they compare two versions of a type system, synthesizing a program accepted by one but rejected by the other. Third, they minimize the size of synthesized counterexample programs. These algorithms symbolically evaluate typecheckers and interpreters, producing formulas that characterize the set of programs that fail or succeed in the typechecker and the interpreter. However, symbolically evaluating interpreters poses efficiency challenges, which are caused by having to merge execution paths of the various possible input programs. Our main contribution is the bonsai tree, a novel symbolic representation of programs and program states that addresses these challenges. Bonsai trees encode complex syntactic information in terms of logical constraints, enabling more efficient merging. We implement these algorithms in the Bonsai tool, an assistant for type system designers. We perform case studies on how Bonsai helps test and explore a variety of type systems. Bonsai efficiently synthesizes counterexamples for soundness bugs previously inaccessible to automatic tools and is the first automated tool to find a counterexample for the recently discovered Scala soundness bug SI-9633.},
  journal    = {Proceedings of the ACM on Programming Languages},
  month      = {dec},
  articleno  = {62},
  numpages   = {34},
  keywords   = {type checking, symbolic compilation, synthesis}
}


@inproceedings{lin_et_al:LIPIcs:2020:12349,
  author    = {Yu-Yang Lin and Nikos Tzevelekos},
  title     = {{Symbolic Execution Game Semantics}},
  booktitle = {5th International Conference on Formal Structures for Computation and Deduction (FSCD 2020)},
  pages     = {27:1--27:24},
  series    = {Leibniz International Proceedings in Informatics (LIPIcs)},
  isbn      = {978-3-95977-155-9},
  issn      = {1868-8969},
  year      = {2020},
  volume    = {167},
  editor    = {Zena M. Ariola},
  publisher = {Schloss Dagstuhl--Leibniz-Zentrum f{\"u}r Informatik},
  address   = {Dagstuhl, Germany},
  url       = {https://drops.dagstuhl.de/opus/volltexte/2020/12349},
  urn       = {urn:nbn:de:0030-drops-123493},
  doi       = {10.4230/LIPIcs.FSCD.2020.27},
  annote    = {Keywords: game semantics, symbolic execution, higher-order open programs}
}

@inproceedings{10.1007/978-3-030-72019-3_23,
  author    = {You, Shu-Hung
               and Findler, Robert Bruce
               and Dimoulas, Christos},
  editor    = {Yoshida, Nobuko},
  title     = {Sound and Complete Concolic Testing for Higher-order Functions},
  booktitle = {Programming Languages and Systems},
  year      = {2021},
  publisher = {Springer International Publishing},
  address   = {Cham},
  pages     = {635--663},
  abstract  = {Higher-order functions have become a staple of modern programming languages. However, such values stymie concolic testers, as the SMT solvers at their hearts are inherently first-order.},
  isbn      = {978-3-030-72019-3}
}


@phdthesis{Moh89b,
  author = {C. Paulin-Mohring},
  month  = jan,
  school = {{Paris 7}},
  title  = {Extraction de programmes dans le {Calcul des Constructions}},
  type   = {Thèse d'université},
  year   = {1989},
  url    = {http://www.lri.fr/~paulin/PUBLIS/these.ps.gz}
}

@inproceedings{151633,
  author    = {Audebaud, P.},
  booktitle = {[1991] Proceedings Sixth Annual IEEE Symposium on Logic in Computer Science},
  title     = {Partial objects in the calculus of constructions},
  year      = {1991},
  volume    = {},
  number    = {},
  pages     = {86-95},
  doi       = {10.1109/LICS.1991.151633}
}

@book{martin-lof:bibliopolis,
  author     = {Martin-L{\"o}f, Per},
  isbn       = {88-7088-105-9},
  mrclass    = {03B15 (03F50 03F55)},
  mrnumber   = {769301 (86j:03005)},
  mrreviewer = {M. M. Richter},
  pages      = {iv+91},
  publisher  = {Bibliopolis},
  series     = {Studies in Proof Theory},
  subtitle   = {Notes by Giovanni Sambin},
  title      = {Intuitionistic type theory},
  volume     = {1},
  year       = {1984}
}

@article{dybjer1994inductive,
  title     = {Inductive families},
  author    = {Dybjer, Peter},
  journal   = {Formal aspects of computing},
  volume    = {6},
  number    = {4},
  pages     = {440--465},
  year      = {1994},
  publisher = {Springer}
}

@manual{Coq12,
  author = {{Coq} {Development} {Team}, The},
  title  = {The {Coq} Reference Manual, version 8.4},
  month  = Aug,
  year   = {2012},
  note   = {Available electronically at \url{http://coq.inria.fr/doc}}
}


@inproceedings{10.1007/978-3-030-79876-5_37,
  author    = {Moura, Leonardo de
               and Ullrich, Sebastian},
  editor    = {Platzer, Andr{\'e}
               and Sutcliffe, Geoff},
  title     = {The Lean 4 Theorem Prover and Programming Language},
  booktitle = {Automated Deduction -- CADE 28},
  year      = {2021},
  publisher = {Springer International Publishing},
  address   = {Cham},
  pages     = {625--635},
  abstract  = {Lean 4 is a reimplementation of the Lean interactive theorem prover (ITP) in Lean itself. It addresses many shortcomings of the previous versions and contains many new features. Lean 4 is fully extensible: users can modify and extend the parser, elaborator, tactics, decision procedures, pretty printer, and code generator. The new system has a hygienic macro system custom-built for ITPs. It contains a new typeclass resolution procedure based on tabled resolution, addressing significant performance problems reported by the growing user base. Lean 4 is also an efficient functional programming language based on a novel programming paradigm called functional but in-place. Efficient code generation is crucial for Lean users because many write custom proof automation procedures in Lean itself.},
  isbn      = {978-3-030-79876-5}
}


@inproceedings{10.1145/3293880.3294101,
  author    = {Stark, Kathrin and Sch\"{a}fer, Steven and Kaiser, Jonas},
  title     = {Autosubst 2: Reasoning with Multi-Sorted de Bruijn Terms and Vector Substitutions},
  year      = {2019},
  isbn      = {9781450362221},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3293880.3294101},
  doi       = {10.1145/3293880.3294101},
  abstract  = {Formalising metatheory in the Coq proof assistant is tedious as reasoning with binders without native support requires a lot of uninteresting technicalities. To relieve users from so-produced boilerplate, the Autosubst framework automates working with de Bruijn terms: For each annotated inductive type, Autosubst generates a corresponding instantiation operation for parallel substitutions and a decision procedure for assumption-free substitution lemmas. However, Autosubst is implemented in Ltac, Coq's tactic language, and thus suffers from Ltac's limitations. In particular, Autosubst is restricted to Coq and unscoped, non-mutual inductive types with a single sort of variables. In this paper, we present a new version of Autosubst that overcomes these restrictions. Autosubst 2 is an external code generator, which translates second-order HOAS specifications into potentially mutual inductive term sorts. We extend the equational theory of Autosubst to the case of mutual inductive sorts by combining the application of multiple parallel substitutions into exactly one instantiation operation for each sort, i.e. we parallelise substitutions to vector substitutions. The resulting equational theory is both simpler and more expressive than that of the original Autosubst framework and allows us to present an even more elegant proof of part A of the POPLMark challenge.},
  booktitle = {Proceedings of the 8th ACM SIGPLAN International Conference on Certified Programs and Proofs},
  pages     = {166--180},
  numpages  = {15},
  keywords  = {parallel substiutions, de Bruijn repersentation, sigma-calculus, multi-sorted terms},
  location  = {Cascais, Portugal},
  series    = {CPP 2019}
}


@inbook{Leibniz1989,
  author    = {Leibniz, Gottfried Wilhelm},
  editor    = {Loemker, Leroy E.},
  title     = {Discourse on Metaphysics},
  booktitle = {Philosophical Papers and Letters},
  year      = {1989},
  publisher = {Springer Netherlands},
  address   = {Dordrecht},
  pages     = {303--330},
  abstract  = {The first mature synthesis of Leibniz's philosophical opinions is an essay without title which is described in a letter to the Landgrave Ernest of Hesse-Rheinfels on February 1/11,1686.},
  isbn      = {978-94-010-1426-7},
  doi       = {10.1007/978-94-010-1426-7_36},
  url       = {https://doi.org/10.1007/978-94-010-1426-7_36}
}

@misc{Leibniz1686,
  author = {Leibniz, Gottfried Wilhelm},
  title  = {Discours de métaphysique},
  year   = {1686}
}

@book{pitts_dybjer_1997,
  place      = {Cambridge},
  series     = {Publications of the Newton Institute},
  title      = {Semantics and Logics of Computation},
  doi        = {10.1017/CBO9780511526619},
  publisher  = {Cambridge University Press},
  year       = {1997},
  collection = {Publications of the Newton Institute}
}

@inbook{hofmann_1997,
  place      = {Cambridge},
  series     = {Publications of the Newton Institute},
  title      = {Syntax and Semantics of Dependent Types},
  doi        = {10.1017/CBO9780511526619.004},
  booktitle  = {Semantics and Logics of Computation},
  publisher  = {Cambridge University Press},
  author     = {Hofmann, Martin},
  editor     = {Pitts, Andrew M. and Dybjer, P.Editors},
  year       = {1997},
  pages      = {79--130},
  collection = {Publications of the Newton Institute}
}

@article{chlipala2017formal,
  title   = {Formal reasoning about programs},
  author  = {Chlipala, Adam},
  journal = {url: http://adam. chlipala. net/frap},
  year    = {2017}
}

@article{VAKAR2018401,
  title    = {Game semantics for dependent types},
  journal  = {Information and Computation},
  volume   = {261},
  pages    = {401-431},
  year     = {2018},
  note     = {ICALP 2015},
  issn     = {0890-5401},
  doi      = {https://doi.org/10.1016/j.ic.2018.02.015},
  url      = {https://www.sciencedirect.com/science/article/pii/S089054011830018X},
  author   = {Matthijs Vákár and Radha Jagadeesan and Samson Abramsky},
  keywords = {Game semantics, Dependent type theory, Intensionality},
  abstract = {We present a model of dependent type theory (DTT) with Π-, 1-, Σ- and intensional Id-types, which is based on a slight variation of the (call-by-name) category of AJM-games and history-free winning well-bracketed strategies. The model satisfies Streicher's criteria of intensionality and refutes function extensionality. The principle of uniqueness of identity proofs is satisfied. We show it contains a submodel as a full subcategory which gives a faithful interpretation of DTT with Π-, 1-, Σ- and intensional Id-types and, additionally, finite inductive type families. This smaller model is fully (and faithfully) complete with respect to the syntax at the type hierarchy built without Id-types, as well as at the more general class of types where we allow for one strictly positive occurrence of an Id-type. Definability for the full type hierarchy with Id-types remains to be investigated.}
}

@article{PALMGREN1990135,
  title   = {Domain interpretations of martin-löf’s partial type theory},
  journal = {Annals of Pure and Applied Logic},
  volume  = {48},
  number  = {2},
  pages   = {135-196},
  year    = {1990},
  issn    = {0168-0072},
  doi     = {https://doi.org/10.1016/0168-0072(90)90044-3},
  url     = {https://www.sciencedirect.com/science/article/pii/0168007290900443},
  author  = {Erik Palmgren and Viggo Stoltenberg-Hansen}
}

@inproceedings{10.1007/978-3-642-12251-4_5,
  author    = {Altenkirch, Thorsten
               and Danielsson, Nils Anders
               and L{\"o}h, Andres
               and Oury, Nicolas},
  editor    = {Blume, Matthias
               and Kobayashi, Naoki
               and Vidal, Germ{\'a}n},
  title     = {$\Pi\Sigma$: Dependent Types without the Sugar},
  booktitle = {Functional and Logic Programming},
  year      = {2010},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {40--55},
  abstract  = {The recent success of languages like Agda and Coq demonstrates the potential of using dependent types for programming. These systems rely on many high-level features like datatype definitions, pattern matching and implicit arguments to facilitate the use of the languages. However, these features complicate the metatheoretical study and are a potential source of bugs.},
  isbn      = {978-3-642-12251-4}
}

@article{10.2307/1968337,
  issn      = {0003486X},
  url       = {http://www.jstor.org/stable/1968337},
  author    = {Alonzo Church},
  journal   = {Annals of Mathematics},
  number    = {2},
  pages     = {346--366},
  publisher = {Annals of Mathematics},
  title     = {A Set of Postulates for the Foundation of Logic},
  volume    = {33},
  year      = {1932}
}

@inproceedings{lemay2019understanding,
  title        = {Understanding Java usability by mining GitHub repositories},
  author       = {Lemay, Mark J},
  booktitle    = {9th Workshop on Evaluation and Usability of Programming Languages and Tools (PLATEAU 2018)},
  year         = {2019},
  organization = {Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik}
}

@inproceedings{lemay2017automated,
  title     = {Automated provenance analytics: A regular grammar based approach with applications in security},
  author    = {Lemay, Mark and Hassan, Wajih Ul and Moyer, Thomas and Schear, Nabil and Smith, Warren},
  booktitle = {9th USENIX Workshop on the Theory and Practice of Provenance},
  year      = {2017}
}

@inproceedings{hassan2018towards,
  title     = {Towards scalable cluster auditing through grammatical inference over provenance graphs},
  author    = {Hassan, Wajih Ul and Mark, Lemay and Aguse, Nuraini and Bates, Adam and Moyer, Thomas},
  booktitle = {Network and Distributed Systems Security Symposium},
  year      = {2018}
}

@book{streicher2006domain,
  title={Domain-theoretic foundations of functional programming},
  author={Streicher, Thomas},
  year={2006},
  publisher={World Scientific Publishing Company}
}

@techreport{veldhuizen2003,
  title={C++ templates are turing complete},
  author={Veldhuizen, Todd L},
  year={2003},
  institution = {Indiana University Computer Science}
}

@article{10.1145/3093333.3009871,
author = {Grigore, Radu},
title = {Java Generics Are Turing Complete},
year = {2017},
issue_date = {January 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {1},
issn = {0362-1340},
url = {https://doi.org/10.1145/3093333.3009871},
doi = {10.1145/3093333.3009871},
abstract = { This paper describes a reduction from the halting problem of Turing machines to subtype checking in Java. It follows that subtype checking in Java is undecidable, which answers a question posed by Kennedy and Pierce in 2007. It also follows that Java's type checker can recognize any recursive language, which improves a result of Gill and Levy from 2016. The latter point is illustrated by a parser generator for fluent interfaces. },
journal = {SIGPLAN Notices},
month = {jan},
pages = {73–85},
numpages = {13},
keywords = {parser generator, fluent interface, decidability, Turing machine, Java, subtype checking}
}

@online{Rossberg1999OCaml,
  author = {Rossberg, Andreas},
  title = {Undecidability of OCaml type checking},
  year = 1999,
  url = {https://caml.inria.fr/pub/old_caml_site/caml-list/1507.html}
}

@InProceedings{10.1007/3-540-06859-7_148,
author="Reynolds, John C.",
editor="Robinet, B.",
title="Towards a theory of type structure",
booktitle="Programming Symposium",
year="1974",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="408--425",
isbn="978-3-540-37819-8"
}
